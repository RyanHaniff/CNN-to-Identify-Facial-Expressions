{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "MyQ4QFbZVhuG"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UB6z6XFaWdcv",
    "outputId": "c1b8540b-5e75-4fdd-c50e-6f4d89436a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2760 files belonging to 7 classes.\n",
      "Found 1440 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# get training and validation(=testing) data\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../COMP_473_Project/TrainSet1-new',\n",
    "    image_size = (48,48), # our original dataset is 48 pixels by 48 pixels\n",
    "    batch_size = 12, # pick 12 images and trim until all dataset is used <= repeat this for each epoche\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../COMP_473_Project/TestSet1-new',\n",
    "    image_size = (48,48), \n",
    "    batch_size = 12,\n",
    "    color_mode='grayscale'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDTPOOojvWc4",
    "outputId": "307a2019-d9ec-4c0c-9bfa-7c02d28c28b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<BatchDataset element_spec=(TensorSpec(shape=(None, 48, 48, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds \n",
    "# form shape=(None, 48, 48, 3) <- 3 represent that the photo is treated as colored. one pixel will have [R G B] values between 0~255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nlxVewnivXWB",
    "outputId": "cdfa1795-48ef-413a-c428-962b243be067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [ 22.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [ 21.]\n",
      "   [  2.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[ 41.]\n",
      "   [  3.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [ 41.]\n",
      "   [  8.]\n",
      "   [  0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0.]\n",
      "   [  9.]\n",
      "   [ 37.]\n",
      "   ...\n",
      "   [ 38.]\n",
      "   [ 44.]\n",
      "   [ 45.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  6.]\n",
      "   [ 41.]\n",
      "   ...\n",
      "   [ 10.]\n",
      "   [  7.]\n",
      "   [  4.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  4.]\n",
      "   [ 41.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]]\n",
      "\n",
      "\n",
      " [[[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]]\n",
      "\n",
      "\n",
      " [[[  0.]\n",
      "   [  0.]\n",
      "   [107.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [ 10.]\n",
      "   [109.]\n",
      "   ...\n",
      "   [ 13.]\n",
      "   [ 15.]\n",
      "   [ 11.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [ 17.]\n",
      "   [108.]\n",
      "   ...\n",
      "   [ 53.]\n",
      "   [ 96.]\n",
      "   [118.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 83.]\n",
      "   [ 57.]\n",
      "   [ 47.]\n",
      "   ...\n",
      "   [ 93.]\n",
      "   [ 24.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  5.]\n",
      "   [  7.]\n",
      "   ...\n",
      "   [ 91.]\n",
      "   [ 14.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [ 89.]\n",
      "   [  8.]\n",
      "   [  0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 39.]\n",
      "   [ 31.]\n",
      "   [ 12.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[ 36.]\n",
      "   [ 32.]\n",
      "   [  9.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  1.]]\n",
      "\n",
      "  [[ 38.]\n",
      "   [ 26.]\n",
      "   [  5.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 47.]\n",
      "   [ 48.]\n",
      "   [ 48.]\n",
      "   ...\n",
      "   [ 54.]\n",
      "   [ 53.]\n",
      "   [ 53.]]\n",
      "\n",
      "  [[ 48.]\n",
      "   [ 48.]\n",
      "   [ 48.]\n",
      "   ...\n",
      "   [ 54.]\n",
      "   [ 53.]\n",
      "   [ 53.]]\n",
      "\n",
      "  [[ 47.]\n",
      "   [ 47.]\n",
      "   [ 48.]\n",
      "   ...\n",
      "   [ 56.]\n",
      "   [ 56.]\n",
      "   [ 54.]]]\n",
      "\n",
      "\n",
      " [[[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [147.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [ 11.]\n",
      "   [ 15.]\n",
      "   ...\n",
      "   [152.]\n",
      "   [ 14.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[115.]\n",
      "   [121.]\n",
      "   [ 95.]\n",
      "   ...\n",
      "   [161.]\n",
      "   [ 25.]\n",
      "   [  0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0.]\n",
      "   [ 29.]\n",
      "   [115.]\n",
      "   ...\n",
      "   [130.]\n",
      "   [128.]\n",
      "   [126.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [ 18.]\n",
      "   [114.]\n",
      "   ...\n",
      "   [ 33.]\n",
      "   [ 20.]\n",
      "   [ 12.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [ 11.]\n",
      "   [113.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]]\n",
      "\n",
      "\n",
      " [[[ 21.]\n",
      "   [ 15.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [ 86.]\n",
      "   [ 75.]\n",
      "   [ 74.]]\n",
      "\n",
      "  [[ 26.]\n",
      "   [ 10.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [ 80.]\n",
      "   [ 78.]\n",
      "   [ 76.]]\n",
      "\n",
      "  [[  7.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [ 59.]\n",
      "   [ 76.]\n",
      "   [ 77.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 29.]\n",
      "   [ 18.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  3.]\n",
      "   [  1.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[ 29.]\n",
      "   [  6.]\n",
      "   [  1.]\n",
      "   ...\n",
      "   [  2.]\n",
      "   [  1.]\n",
      "   [  6.]]\n",
      "\n",
      "  [[  2.]\n",
      "   [  1.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [ 13.]\n",
      "   [  1.]\n",
      "   [  3.]]]], shape=(12, 48, 48, 1), dtype=float32)\n",
      "tf.Tensor([4 6 6 6 4 2 3 4 3 5 6 5], shape=(12,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'In a grayscale image where there is only one channel, a pixel value has just a single number ranging from 0 to 255 (both inclusive).\\n The pixel value 0 represents black and the pixel value 255 represents white.\\n [ 80.] is closer to black than white therefore showing black'"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to output one of our image\n",
    "\n",
    "for i, answer in train_ds.take(1): #take(1): takes first batch. \n",
    "\n",
    "  print(i) # outputs 12(=batch size) photos as numpy array ,shape=(12, 48, 48, 3) means 12 photos, each photo size(48,48 pixels), 3=color= each cell represented as [R G B]\n",
    "  print(answer) # outputs correct answer for current batch [ 5 2 6 ...] <- first photo in this batch is in class 5, second photo in this patch is in class 2.. \n",
    "\n",
    "plt.imshow(i[0].numpy().astype('uint8'), cmap='gray', vmin=0, vmax=255) # output the first photo using matplotlib\n",
    "plt.show()\n",
    "'''In a grayscale image where there is only one channel, a pixel value has just a single number ranging from 0 to 255 (both inclusive).\n",
    " The pixel value 0 represents black and the pixel value 255 represents white.\n",
    " [ 80.] is closer to black than white therefore showing black'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "pEoV-cdH1lGq"
   },
   "outputs": [],
   "source": [
    "# preprocess colored data\n",
    "# since the numbers are between 0~255 for each R, G, and B, it is slower to train and calculate weights.\n",
    "# it is better to divide each number with 255, so each value resides within 0~1\n",
    "\n",
    "\n",
    "\n",
    "def processGrayScaleData(i, answer):\n",
    "  i=tf.cast(i/255.0, tf.float32) # divide i by 255, resulting data type should be float\n",
    "  return i, answer\n",
    "\n",
    "train_ds = train_ds.map(processGrayScaleData)\n",
    "val_ds = val_ds.map(processGrayScaleData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bid7gMcW1se5",
    "outputId": "b760f03f-92c5-49d5-cf67-54a4d31e2849"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.08235294]\n",
      "   [0.05882353]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.3372549 ]\n",
      "   [0.29411766]\n",
      "   [0.2901961 ]]\n",
      "\n",
      "  [[0.10196079]\n",
      "   [0.03921569]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.3137255 ]\n",
      "   [0.30588236]\n",
      "   [0.29803923]]\n",
      "\n",
      "  [[0.02745098]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.23137255]\n",
      "   [0.29803923]\n",
      "   [0.3019608 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.11372549]\n",
      "   [0.07058824]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.01176471]\n",
      "   [0.00392157]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.11372549]\n",
      "   [0.02352941]\n",
      "   [0.00392157]\n",
      "   ...\n",
      "   [0.00784314]\n",
      "   [0.00392157]\n",
      "   [0.02352941]]\n",
      "\n",
      "  [[0.00784314]\n",
      "   [0.00392157]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.05098039]\n",
      "   [0.00392157]\n",
      "   [0.01176471]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.34901962]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.34509805]\n",
      "   [0.03137255]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.34117648]\n",
      "   [0.05490196]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.07450981]\n",
      "   [0.29411766]\n",
      "   ...\n",
      "   [0.34117648]\n",
      "   [0.33333334]\n",
      "   [0.32941177]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.04705882]\n",
      "   [0.29411766]\n",
      "   ...\n",
      "   [0.08627451]\n",
      "   [0.05098039]\n",
      "   [0.03137255]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.02745098]\n",
      "   [0.2901961 ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.5647059 ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.01960784]\n",
      "   [0.01960784]\n",
      "   ...\n",
      "   [0.57254905]\n",
      "   [0.05490196]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.3254902 ]\n",
      "   [0.2       ]\n",
      "   [0.13333334]\n",
      "   ...\n",
      "   [0.5647059 ]\n",
      "   [0.09019608]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.11764706]\n",
      "   [0.46666667]\n",
      "   ...\n",
      "   [0.5882353 ]\n",
      "   [0.5019608 ]\n",
      "   [0.47843137]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.07058824]\n",
      "   [0.45882353]\n",
      "   ...\n",
      "   [0.16078432]\n",
      "   [0.07843138]\n",
      "   [0.04313726]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.04313726]\n",
      "   [0.4509804 ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]], shape=(12, 48, 48, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# try to output our image if 'processColoredData' function is working well.\n",
    "for i, answer in train_ds.take(1): #take first batch \n",
    "  print(i) # now you can see that the values are compressed btw 0~1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pi4bprpl1_3u",
    "outputId": "22c60923-5deb-4d96-9177-08e5b8a0f982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 48, 48, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 24, 24, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 12, 12, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 6, 6, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                294976    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388,103\n",
      "Trainable params: 388,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "230/230 [==============================] - 5s 17ms/step - loss: 1.5680 - accuracy: 0.3721 - val_loss: 0.9684 - val_accuracy: 0.6229\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.7528 - accuracy: 0.6851 - val_loss: 0.7530 - val_accuracy: 0.7160\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.5573 - accuracy: 0.7493 - val_loss: 0.7114 - val_accuracy: 0.7431\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.4701 - accuracy: 0.7942 - val_loss: 0.7049 - val_accuracy: 0.7507\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.4465 - accuracy: 0.8007 - val_loss: 0.6517 - val_accuracy: 0.7549\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3552 - accuracy: 0.8420 - val_loss: 0.7529 - val_accuracy: 0.7743\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3309 - accuracy: 0.8540 - val_loss: 0.7276 - val_accuracy: 0.7785\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3120 - accuracy: 0.8725 - val_loss: 0.6813 - val_accuracy: 0.8062\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.2709 - accuracy: 0.8783 - val_loss: 0.6818 - val_accuracy: 0.8090\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.2706 - accuracy: 0.8855 - val_loss: 0.7741 - val_accuracy: 0.7799\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1f6ca2807f0>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making model\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "\n",
    "    # .conv2D : with feature extraction we can expect higher accuracy               \n",
    "    # 1st param: make 32 different features. use such features to train better model. \n",
    "    # 2nd param: kernel size is 3x3\n",
    "    # 3rd param: when using convolutional layer, (=when kernel is applied to each photo) the size of photo will shrink. we will put some padding here to retain 48*48 size even after feature extraction.\n",
    "    # 4th param: activation function. relu compress number to 0~1. There's no negative number in photo so it is good to use relu.\n",
    "    # 5th param: input_shape : shape of one photo data\n",
    "    tf.keras.layers.Conv2D( 32, (3,3), padding='same' , activation='relu', input_shape=(48,48,1)), # set input_shape=(48,48,3) from 3 to 1 since we are passing in grayscale\n",
    "    \n",
    "    \n",
    "    # pooling layer (Downsampling)\n",
    "    # downsize 2,2 pixels to 1,1\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    # helps prevent overfittng ( randomly sets input units to 0 with frequency of rate)\n",
    "    tf.keras.layers.Dropout(0.2), \n",
    "\n",
    "    # It is okay to repeat [Conv-Pooling] several times\n",
    "    # we will repeat [Conv-Pooling] two more times to increase learning effect\n",
    "    tf.keras.layers.Conv2D( 64, (3,3), padding='same' , activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D((2,2)), \n",
    "        \n",
    "    tf.keras.layers.Conv2D( 128, (3,3), padding='same' , activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D((2,2)), \n",
    "\n",
    "\n",
    "    # Flatten-Dense\n",
    "    tf.keras.layers.Flatten(), \n",
    "    ## 1st layer\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"), # number inside Dense is the number of nodes. usually use 2^n\n",
    "    tf.keras.layers.Dropout(0.2), # helps prevent overfittng\n",
    "    ## second layer. we must have 7 final nodes because we have 7 classes.\n",
    "    tf.keras.layers.Dense(7, activation=\"softmax\") # softmax: compress resulting number between 0~1, used in category problems. If you add up the probability of each class we get 1. \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# prints summary of our model. \n",
    "model.summary()\n",
    "\n",
    "\n",
    "# compile and fit our model\n",
    "# epochs tells us the number of times model will be trained in forward and backward pass.\n",
    "# validation_data is used to feed the validation/test data into the model.\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\" , metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save model weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "model.save_weights('model_saved.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting a test set:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2034038034.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn [70], line 12\u001B[1;36m\u001B[0m\n\u001B[1;33m    for img in\u001B[0m\n\u001B[1;37m               ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model_saved.h5')\n",
    "\n",
    "test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../COMP_473_Project/TrainSet1-new',\n",
    "    image_size = (48,48),\n",
    "    batch_size = 12,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "for img in"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "96762580dc771c728ac9a1b8aa29a3a420bc09545a8c1a32553175fbb1f6eb2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
