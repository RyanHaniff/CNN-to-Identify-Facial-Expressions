{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "MyQ4QFbZVhuG"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UB6z6XFaWdcv",
    "outputId": "c1b8540b-5e75-4fdd-c50e-6f4d89436a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1440 files belonging to 7 classes.\n",
      "Found 2760 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# get training and validation(=testing) data\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../COMP_473_Project/TestSet1-new',\n",
    "    image_size = (48,48), # our original dataset is 48 pixels by 48 pixels\n",
    "    batch_size = 12, # pick 12 images and trim until all dataset is used <= repeat this for each epoche\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../COMP_473_Project/TrainSet1-new',\n",
    "    image_size = (48,48), \n",
    "    batch_size = 12,\n",
    "    color_mode='grayscale'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDTPOOojvWc4",
    "outputId": "307a2019-d9ec-4c0c-9bfa-7c02d28c28b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<BatchDataset element_spec=(TensorSpec(shape=(None, 48, 48, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds \n",
    "# form shape=(None, 48, 48, 3) <- 3 represent that the photo is treated as colored. one pixel will have [R G B] values between 0~255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nlxVewnivXWB",
    "outputId": "cdfa1795-48ef-413a-c428-962b243be067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 93.]\n",
      "   [ 95.]\n",
      "   [ 95.]\n",
      "   ...\n",
      "   [118.]\n",
      "   [116.]\n",
      "   [115.]]\n",
      "\n",
      "  [[ 94.]\n",
      "   [ 95.]\n",
      "   [ 97.]\n",
      "   ...\n",
      "   [117.]\n",
      "   [116.]\n",
      "   [118.]]\n",
      "\n",
      "  [[ 93.]\n",
      "   [ 95.]\n",
      "   [ 97.]\n",
      "   ...\n",
      "   [116.]\n",
      "   [118.]\n",
      "   [119.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 76.]\n",
      "   [ 80.]\n",
      "   [ 82.]\n",
      "   ...\n",
      "   [ 99.]\n",
      "   [ 98.]\n",
      "   [ 97.]]\n",
      "\n",
      "  [[ 76.]\n",
      "   [ 79.]\n",
      "   [ 80.]\n",
      "   ...\n",
      "   [ 99.]\n",
      "   [ 98.]\n",
      "   [ 96.]]\n",
      "\n",
      "  [[ 73.]\n",
      "   [ 76.]\n",
      "   [ 79.]\n",
      "   ...\n",
      "   [ 99.]\n",
      "   [ 95.]\n",
      "   [ 94.]]]\n",
      "\n",
      "\n",
      " [[[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]]\n",
      "\n",
      "\n",
      " [[[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[251.]\n",
      "   [252.]\n",
      "   [254.]\n",
      "   ...\n",
      "   [ 31.]\n",
      "   [ 30.]\n",
      "   [ 35.]]\n",
      "\n",
      "  [[251.]\n",
      "   [255.]\n",
      "   [174.]\n",
      "   ...\n",
      "   [ 47.]\n",
      "   [ 32.]\n",
      "   [ 33.]]\n",
      "\n",
      "  [[255.]\n",
      "   [205.]\n",
      "   [ 69.]\n",
      "   ...\n",
      "   [ 60.]\n",
      "   [ 38.]\n",
      "   [ 35.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 30.]\n",
      "   [ 28.]\n",
      "   [ 28.]\n",
      "   ...\n",
      "   [ 16.]\n",
      "   [ 16.]\n",
      "   [ 16.]]\n",
      "\n",
      "  [[ 30.]\n",
      "   [ 29.]\n",
      "   [ 33.]\n",
      "   ...\n",
      "   [ 16.]\n",
      "   [ 17.]\n",
      "   [ 16.]]\n",
      "\n",
      "  [[ 26.]\n",
      "   [ 30.]\n",
      "   [ 34.]\n",
      "   ...\n",
      "   [ 16.]\n",
      "   [ 18.]\n",
      "   [ 17.]]]\n",
      "\n",
      "\n",
      " [[[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]]\n",
      "\n",
      "\n",
      " [[[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]\n",
      "\n",
      "  [[  0.]\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [  0.]\n",
      "   [  0.]]]], shape=(12, 48, 48, 1), dtype=float32)\n",
      "tf.Tensor([4 4 4 2 2 4 0 4 5 3 6 1], shape=(12,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'In a grayscale image where there is only one channel, a pixel value has just a single number ranging from 0 to 255 (both inclusive).\\n The pixel value 0 represents black and the pixel value 255 represents white.\\n [ 80.] is closer to black than white therefore showing black'"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to output one of our image\n",
    "\n",
    "for i, answer in train_ds.take(1): #take(1): takes first batch. \n",
    "\n",
    "  print(i) # outputs 12(=batch size) photos as numpy array ,shape=(12, 48, 48, 3) means 12 photos, each photo size(48,48 pixels), 3=color= each cell represented as [R G B]\n",
    "  print(answer) # outputs correct answer for current batch [ 5 2 6 ...] <- first photo in this batch is in class 5, second photo in this patch is in class 2.. \n",
    "\n",
    "plt.imshow(i[0].numpy().astype('uint8'), cmap='gray', vmin=0, vmax=255) # output the first photo using matplotlib\n",
    "plt.show()\n",
    "'''In a grayscale image where there is only one channel, a pixel value has just a single number ranging from 0 to 255 (both inclusive).\n",
    " The pixel value 0 represents black and the pixel value 255 represents white.\n",
    " [ 80.] is closer to black than white therefore showing black'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "pEoV-cdH1lGq"
   },
   "outputs": [],
   "source": [
    "# preprocess colored data\n",
    "# since the numbers are between 0~255 for each R, G, and B, it is slower to train and calculate weights.\n",
    "# it is better to divide each number with 255, so each value resides within 0~1\n",
    "\n",
    "\n",
    "\n",
    "def processGrayScaleData(i, answer):\n",
    "  i=tf.cast(i/255.0, tf.float32) # divide i by 255, resulting data type should be float\n",
    "  return i, answer\n",
    "\n",
    "train_ds = train_ds.map(processGrayScaleData)\n",
    "val_ds = val_ds.map(processGrayScaleData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bid7gMcW1se5",
    "outputId": "b760f03f-92c5-49d5-cf67-54a4d31e2849"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.20392157]\n",
      "   [0.12941177]\n",
      "   [0.02352941]\n",
      "   ...\n",
      "   [0.24705882]\n",
      "   [0.27450982]\n",
      "   [0.3019608 ]]\n",
      "\n",
      "  [[0.14117648]\n",
      "   [0.03921569]\n",
      "   [0.00784314]\n",
      "   ...\n",
      "   [0.1764706 ]\n",
      "   [0.23529412]\n",
      "   [0.2784314 ]]\n",
      "\n",
      "  [[0.04705882]\n",
      "   [0.01568628]\n",
      "   [0.00784314]\n",
      "   ...\n",
      "   [0.07843138]\n",
      "   [0.1882353 ]\n",
      "   [0.26666668]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.26666668]\n",
      "   [0.2627451 ]\n",
      "   [0.25882354]\n",
      "   ...\n",
      "   [0.3019608 ]\n",
      "   [0.3019608 ]\n",
      "   [0.29803923]]\n",
      "\n",
      "  [[0.27058825]\n",
      "   [0.26666668]\n",
      "   [0.27058825]\n",
      "   ...\n",
      "   [0.29803923]\n",
      "   [0.29803923]\n",
      "   [0.29411766]]\n",
      "\n",
      "  [[0.2627451 ]\n",
      "   [0.27058825]\n",
      "   [0.27058825]\n",
      "   ...\n",
      "   [0.29803923]\n",
      "   [0.3019608 ]\n",
      "   [0.29803923]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.28235295]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.02352941]\n",
      "   [0.23921569]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.01176471]\n",
      "   [0.03137255]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.03137255]\n",
      "   [0.19215687]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.08235294]\n",
      "   [0.34509805]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.29411766]\n",
      "   [0.3019608 ]\n",
      "   [0.30980393]\n",
      "   ...\n",
      "   [0.34509805]\n",
      "   [0.08627451]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.02745098]\n",
      "   [0.04705882]\n",
      "   ...\n",
      "   [0.34117648]\n",
      "   [0.05490196]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.3372549 ]\n",
      "   [0.03137255]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.3647059 ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.03529412]\n",
      "   [0.08235294]\n",
      "   ...\n",
      "   [0.3019608 ]\n",
      "   [0.02745098]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.45490196]\n",
      "   [0.3882353 ]\n",
      "   [0.53333336]\n",
      "   ...\n",
      "   [0.29803923]\n",
      "   [0.04705882]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.12941177]\n",
      "   [0.5058824 ]\n",
      "   ...\n",
      "   [0.15294118]\n",
      "   [0.21960784]\n",
      "   [0.21960784]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.07450981]\n",
      "   [0.4627451 ]\n",
      "   ...\n",
      "   [0.03921569]\n",
      "   [0.03529412]\n",
      "   [0.01960784]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.03921569]\n",
      "   [0.4       ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.19607843]\n",
      "   [0.1882353 ]\n",
      "   [0.03921569]\n",
      "   ...\n",
      "   [0.05098039]\n",
      "   [0.05490196]\n",
      "   [0.05490196]]\n",
      "\n",
      "  [[0.1882353 ]\n",
      "   [0.14509805]\n",
      "   [0.00784314]\n",
      "   ...\n",
      "   [0.05098039]\n",
      "   [0.04705882]\n",
      "   [0.05098039]]\n",
      "\n",
      "  [[0.19215687]\n",
      "   [0.10588235]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.04705882]\n",
      "   [0.03921569]\n",
      "   [0.03921569]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.17254902]\n",
      "   [0.16862746]\n",
      "   [0.17254902]\n",
      "   ...\n",
      "   [0.00392157]\n",
      "   [0.03921569]\n",
      "   [0.03529412]]\n",
      "\n",
      "  [[0.17254902]\n",
      "   [0.16862746]\n",
      "   [0.15294118]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.05098039]\n",
      "   [0.08627451]]\n",
      "\n",
      "  [[0.17254902]\n",
      "   [0.16078432]\n",
      "   [0.18431373]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.05098039]\n",
      "   [0.12156863]]]], shape=(12, 48, 48, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# try to output our image if 'processColoredData' function is working well.\n",
    "for i, answer in train_ds.take(1): #take first batch \n",
    "  print(i) # now you can see that the values are compressed btw 0~1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pi4bprpl1_3u",
    "outputId": "22c60923-5deb-4d96-9177-08e5b8a0f982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 48, 48, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 24, 24, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                294976    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388,103\n",
      "Trainable params: 388,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 1.7130 - accuracy: 0.2958 - val_loss: 1.5412 - val_accuracy: 0.5348\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.9246 - accuracy: 0.6458 - val_loss: 1.2798 - val_accuracy: 0.5540\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.6028 - accuracy: 0.7736 - val_loss: 1.3256 - val_accuracy: 0.6279\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.4169 - accuracy: 0.8326 - val_loss: 1.7344 - val_accuracy: 0.6091\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.2980 - accuracy: 0.8840 - val_loss: 1.6819 - val_accuracy: 0.6902\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.2187 - accuracy: 0.9201 - val_loss: 1.9742 - val_accuracy: 0.6761\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1906 - accuracy: 0.9299 - val_loss: 2.2209 - val_accuracy: 0.6428\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1673 - accuracy: 0.9396 - val_loss: 2.6591 - val_accuracy: 0.6841\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1835 - accuracy: 0.9271 - val_loss: 1.8789 - val_accuracy: 0.6837\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.1450 - accuracy: 0.9500 - val_loss: 2.0167 - val_accuracy: 0.7029\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1f6c9db7af0>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making model\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "\n",
    "    # .conv2D : with feature extraction we can expect higher accuracy               \n",
    "    # 1st param: make 32 different features. use such features to train better model. \n",
    "    # 2nd param: kernel size is 3x3\n",
    "    # 3rd param: when using convolutional layer, (=when kernel is applied to each photo) the size of photo will shrink. we will put some padding here to retain 48*48 size even after feature extraction.\n",
    "    # 4th param: activation function. relu compress number to 0~1. There's no negative number in photo so it is good to use relu.\n",
    "    # 5th param: input_shape : shape of one photo data\n",
    "    tf.keras.layers.Conv2D( 32, (3,3), padding='same' , activation='relu', input_shape=(48,48,1)), # set input_shape=(48,48,3) from 3 to 1 since we are passing in grayscale\n",
    "    \n",
    "    \n",
    "    # pooling layer (Downsampling)\n",
    "    # downsize 2,2 pixels to 1,1\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    # helps prevent overfittng ( randomly sets input units to 0 with frequency of rate)\n",
    "    tf.keras.layers.Dropout(0.2), \n",
    "\n",
    "    # It is okay to repeat [Conv-Pooling] several times\n",
    "    # we will repeat [Conv-Pooling] two more times to increase learning effect\n",
    "    tf.keras.layers.Conv2D( 64, (3,3), padding='same' , activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D((2,2)), \n",
    "        \n",
    "    tf.keras.layers.Conv2D( 128, (3,3), padding='same' , activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D((2,2)), \n",
    "\n",
    "\n",
    "    # Flatten-Dense\n",
    "    tf.keras.layers.Flatten(), \n",
    "    ## 1st layer\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"), # number inside Dense is the number of nodes. usually use 2^n\n",
    "    tf.keras.layers.Dropout(0.2), # helps prevent overfittng\n",
    "    ## second layer. we must have 7 final nodes because we have 7 classes.\n",
    "    tf.keras.layers.Dense(7, activation=\"softmax\") # softmax: compress resulting number between 0~1, used in category problems. If you add up the probability of each class we get 1. \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# prints summary of our model. \n",
    "model.summary()\n",
    "\n",
    "\n",
    "# compile and fit our model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\" , metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "96762580dc771c728ac9a1b8aa29a3a420bc09545a8c1a32553175fbb1f6eb2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
