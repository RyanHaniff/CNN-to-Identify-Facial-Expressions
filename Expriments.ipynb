{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMP 473 Group Project\n",
    "\n",
    "#### Facial Expression Recognition: 6-Class Classification\n",
    "\n",
    "##### Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Metrics Graph\n",
    "Automatically update loss and accuracy of training and validation set and display the graph as the model gets trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotTrain(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.metrics = {}\n",
    "        for metric in logs:\n",
    "            self.metrics[metric] = []\n",
    "\n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        for metric in logs:\n",
    "            if metric in self.metrics:\n",
    "                self.metrics[metric].append(logs.get(metric))\n",
    "            else:\n",
    "                self.metrics[metric] = [logs.get(metric)]\n",
    "\n",
    "        #To plot the graph\n",
    "        metrics = [x for x in logs if 'val' not in x]\n",
    "\n",
    "        f, axs = plt.subplots(1, len(metrics), figsize = (15,5))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axs[i].plot(range(1, epoch + 2), self.metrics[metric], label=metric)\n",
    "            if logs['val_' + metric]:\n",
    "                axs[i].plot(range(1, epoch + 2), self.metrics['val_' + metric], label = 'val_'+metric)\n",
    "        \n",
    "        axs[i].legend()\n",
    "        axs[i].grid()\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetImport(path):\n",
    "    \n",
    "    data_dir = pathlib.Path('D:\\Concordia\\COMP473\\COMP_473_Project\\CK+')\n",
    "    image_count = len(list(data_dir.glob('*/*.png')))\n",
    "    print(\"total image:\", image_count)\n",
    "\n",
    "    list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\n",
    "    list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n",
    "\n",
    "    #Split between training and test set\n",
    "    test_size = int(image_count * 0.3)\n",
    "    train = list_ds.skip(test_size)\n",
    "    test_ds = list_ds.take(test_size)\n",
    "\n",
    "    #Split within training: training set and validation set\n",
    "    val_size = int(len(train)*0.2)\n",
    "    train_ds = train.skip(val_size)\n",
    "    val_ds = train.take(val_size)\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1545 files belonging to 6 classes.\n",
      "Found 1545 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Replace 'path' with your directory's path\n",
    "\"\"\"\n",
    "path_CK_Augmented = '..\\COMP_473_Project\\CK_Augmented'\n",
    "path_CK_Augmented_ImageCrop = '..\\COMP_473_Project\\CK_Augmented_ImageCrop'\n",
    "\n",
    "# get training and validation data on dataset 1\n",
    "train_CK_Augmented = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_CK_Augmented,\n",
    "    # our original dataset is 48 pixels by 48 pixels\n",
    "    image_size = (48,48),\n",
    "    batch_size = 20,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "\n",
    "train_CK_Augmented_ImageCrop = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_CK_Augmented_ImageCrop,\n",
    "    # our original dataset is 48 pixels by 48 pixels\n",
    "    image_size = (48,48),\n",
    "    batch_size = 20,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Splitting the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [5], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m test_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(train_CK_Augmented)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m.3\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# We then split the training data 80% for training and 20% for validation\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m val_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_size\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m.2\u001B[39m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_size: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(train_size))\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_size: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(test_size))\n",
      "\u001B[1;31mTypeError\u001B[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "# Split the train and test data 70 and 30 % respectively\n",
    "train_size = int(len(train_CK_Augmented)*.7)\n",
    "test_size = int(len(train_CK_Augmented)*.3)\n",
    "\n",
    "# We then split the training data 80% for training and 20% for validation\n",
    "val_size = int(len(train_size)*.2)\n",
    "print('train_size: {}'.format(train_size))\n",
    "print('test_size: {}'.format(test_size))\n",
    "print('val_size: {}'.format(val_size))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Model\n",
    "No Pre-Processing Applied\n",
    "\n",
    "<br>Model1_t1: Trained with Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_t1 = tf.keras.Sequential([\n",
    "    #resize layer to change image into 64x64\n",
    "    tf.keras.layers.Resizing((64,64)),\n",
    "    \n",
    "    # pooling layer (Downsampling)\n",
    "    # downsize 2,2 pixels to 1,1\n",
    "    # change image shape = (32, 32, 3)\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    #input_shape = shape of the images made by Ryan\n",
    "    #kernel size change to 5x5\n",
    "    tf.keras.layers.Conv2D( 32, (5,5), padding='none' , activation='relu', input_shape=(64,64,3)), \n",
    "    \n",
    "    #After Conv2D image shape = (28, 28, 3)\n",
    "    # pooling layer to change image shape = (14, 14, 3)\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    #kernel size change to 7x7\n",
    "    tf.keras.layers.Conv2D(64, (7,7), padding='none' , activation='relu'), \n",
    "    \n",
    "    #After Conv2D image shape = (8, 8, 3)\n",
    "    # pooling layer to change image shape = (4, 4, 3)\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    # Flatten-Dense\n",
    "    tf.keras.layers.Flatten(), \n",
    "    \n",
    "    ## 1st layer\n",
    "    # number inside Dense is the number of nodes. usually use 2^n\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"), \n",
    "    \n",
    "    # helps prevent overfittng\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    ## second layer. we must have 6 final nodes because we have 6 classes.\n",
    "    # softmax: compress resulting number between 0~1, used in category problems. \n",
    "    # If you add up the probability of each class we get 1. \n",
    "    tf.keras.layers.Dense(6, activation=\"softmax\") \n",
    "])\n",
    "\n",
    "model1_t1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and Fit(train) the basic models\n",
    "\n",
    "<br> Model1_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile and fit the model1_t1\n",
    "callback_list = [PlotTrain()]\n",
    "model1_t1.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\" , metrics=['accuracy'])\n",
    "model1_t1.fit(train_ds1, validation_data=val_ds1, epochs=30, callbacks=callback_list)\n",
    "model1_t1.save(\"model1_t1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Test and Results\n",
    "<li> Classification Report\n",
    "<li> Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "classes =['anger', 'contempt', 'disgust','fear','happy', 'sadness','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Conv2D( 32, (3,3), padding='same' , activation='relu', input_shape=(48,48,3)), \n",
    "    \n",
    "    # pooling layer (Downsampling)\n",
    "    # downsize 2,2 pixels to 1,1\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    # Flatten-Dense\n",
    "    tf.keras.layers.Flatten(), \n",
    "    \n",
    "    ## 1st layer\n",
    "    # number inside Dense is the number of nodes. usually use 2^n\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"), \n",
    "    \n",
    "    # helps prevent overfittng\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    ## second layer. we must have 7 final nodes because we have 7 classes.\n",
    "    # softmax: compress resulting number between 0~1, used in category problems. \n",
    "    # If you add up the probability of each class we get 1. \n",
    "    tf.keras.layers.Dense(7, activation=\"softmax\") \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use model.load() to test with each model\n",
    "\n",
    "<br>Model1_t1: Basic model with dataset #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dir = 'pathToTestData'\n",
    "\n",
    "#Fetch testing data from the dataset 1\n",
    "test_dir1 = 'D:\\Concordia\\COMP473\\COMP_473_Project\\TestSet1-new'\n",
    "test_generator1 = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "test_ds1 = test_generator1.flow_from_directory(test_dir1, target_size=(48,48), batch_size=20, shuffle = False)\n",
    "\n",
    "#storing actual class associated with each input image with the correct string label\n",
    "y_true1 = test_ds1.classes\n",
    "true_class1 = []\n",
    "for i in y_true1:\n",
    "    if(i==0):\n",
    "        true_class1+=['anger']\n",
    "    if(i==1):\n",
    "        true_class1+=['contempt']\n",
    "    if(i==2):\n",
    "        true_class1+=['disgust']\n",
    "    if(i==3):\n",
    "        true_class1+=['fear']\n",
    "    if(i==4):\n",
    "        true_class1+=['happy']\n",
    "    if(i==5):\n",
    "        true_class1+=['sadness']\n",
    "    if(i==6):\n",
    "        true_class1+=['surprise']\n",
    "\n",
    "#predict the category with the input images from the test set\n",
    "model.load_weights('model1_t1.h5')\n",
    "y_predict1= model.predict(test_ds1)\n",
    "classes_x1 = np.argmax(y_predict1, axis=1)\n",
    "\n",
    "#change the class labels to string\n",
    "predicted_class1 = []\n",
    "for i in classes_x1:\n",
    "    if(i==0):\n",
    "        predicted_class1+=['anger']\n",
    "    if(i==1):\n",
    "        predicted_class1+=['contempt']\n",
    "    if(i==2):\n",
    "        predicted_class1+=['disgust']\n",
    "    if(i==3):\n",
    "        predicted_class1+=['fear']\n",
    "    if(i==4):\n",
    "        predicted_class1+=['happy']\n",
    "    if(i==5):\n",
    "        predicted_class1+=['sadness']\n",
    "    if(i==6):\n",
    "        predicted_class1+=['surprise']\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(true_class1, predicted_class1))\n",
    "cf_model1 = confusion_matrix(true_class1, predicted_class1, labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cf_model1, display_labels=classes)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41a25e4fc04ae1ac97e89ed19feb20c86178bc3aba5c26b45b17fff7270b24df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
