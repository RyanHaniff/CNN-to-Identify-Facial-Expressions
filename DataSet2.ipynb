{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3465 files belonging to 7 classes.\n",
      "Found 1440 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# get training and validation(=testing) data\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/Users/mantagaori/Desktop/comp473/COMP_473_Project/TrainSet2-new', \n",
    "    image_size = (48,48), # our original dataset is 48 pixels by 48 pixels\n",
    "    batch_size = 20 # pick 12 images and trin until all dataset is used <= repeat this for each epoche\n",
    ")\n",
    "\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/Users/mantagaori/Desktop/comp473/COMP_473_Project/TestSet2-new', \n",
    "    image_size = (48,48), \n",
    "    batch_size = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "174/174 [==============================] - 17s 85ms/step - loss: 18.7310 - accuracy: 0.2234 - val_loss: 1.7503 - val_accuracy: 0.2500\n",
      "Epoch 2/100\n",
      "174/174 [==============================] - 13s 72ms/step - loss: 1.6567 - accuracy: 0.3541 - val_loss: 1.5375 - val_accuracy: 0.4646\n",
      "Epoch 3/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 1.5257 - accuracy: 0.4087 - val_loss: 1.4781 - val_accuracy: 0.4660\n",
      "Epoch 4/100\n",
      "174/174 [==============================] - 13s 73ms/step - loss: 1.5073 - accuracy: 0.4035 - val_loss: 1.4931 - val_accuracy: 0.4674\n",
      "Epoch 5/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 1.5488 - accuracy: 0.3887 - val_loss: 1.4338 - val_accuracy: 0.4611\n",
      "Epoch 6/100\n",
      "174/174 [==============================] - 14s 82ms/step - loss: 1.4807 - accuracy: 0.4043 - val_loss: 1.4423 - val_accuracy: 0.4667\n",
      "Epoch 7/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.4508 - accuracy: 0.4107 - val_loss: 1.3845 - val_accuracy: 0.4681\n",
      "Epoch 8/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.4570 - accuracy: 0.4061 - val_loss: 1.4305 - val_accuracy: 0.4681\n",
      "Epoch 9/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 1.4486 - accuracy: 0.4118 - val_loss: 1.4418 - val_accuracy: 0.4688\n",
      "Epoch 10/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.4424 - accuracy: 0.4115 - val_loss: 1.5316 - val_accuracy: 0.4667\n",
      "Epoch 11/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.4254 - accuracy: 0.4127 - val_loss: 1.6143 - val_accuracy: 0.4667\n",
      "Epoch 12/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.4402 - accuracy: 0.4095 - val_loss: 1.5693 - val_accuracy: 0.4674\n",
      "Epoch 13/100\n",
      "174/174 [==============================] - 13s 72ms/step - loss: 1.4212 - accuracy: 0.4173 - val_loss: 1.5223 - val_accuracy: 0.4694\n",
      "Epoch 14/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.4294 - accuracy: 0.4084 - val_loss: 1.4492 - val_accuracy: 0.4694\n",
      "Epoch 15/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.4507 - accuracy: 0.4055 - val_loss: 1.6578 - val_accuracy: 0.4694\n",
      "Epoch 16/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 1.4465 - accuracy: 0.4147 - val_loss: 1.4521 - val_accuracy: 0.4569\n",
      "Epoch 17/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 1.4628 - accuracy: 0.4023 - val_loss: 1.6564 - val_accuracy: 0.4694\n",
      "Epoch 18/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.4204 - accuracy: 0.4150 - val_loss: 1.6199 - val_accuracy: 0.4681\n",
      "Epoch 19/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.4460 - accuracy: 0.4078 - val_loss: 1.4751 - val_accuracy: 0.4674\n",
      "Epoch 20/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.4339 - accuracy: 0.4101 - val_loss: 1.5849 - val_accuracy: 0.4688\n",
      "Epoch 21/100\n",
      "174/174 [==============================] - 11s 63ms/step - loss: 1.4521 - accuracy: 0.4055 - val_loss: 1.5529 - val_accuracy: 0.4694\n",
      "Epoch 22/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.4234 - accuracy: 0.4170 - val_loss: 1.6206 - val_accuracy: 0.4736\n",
      "Epoch 23/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.4263 - accuracy: 0.4165 - val_loss: 1.8541 - val_accuracy: 0.4604\n",
      "Epoch 24/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.4307 - accuracy: 0.4101 - val_loss: 1.4837 - val_accuracy: 0.4736\n",
      "Epoch 25/100\n",
      "174/174 [==============================] - 12s 71ms/step - loss: 1.4518 - accuracy: 0.4078 - val_loss: 1.6048 - val_accuracy: 0.4694\n",
      "Epoch 26/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.4198 - accuracy: 0.4153 - val_loss: 1.4973 - val_accuracy: 0.4833\n",
      "Epoch 27/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 1.4291 - accuracy: 0.4089 - val_loss: 1.5139 - val_accuracy: 0.4722\n",
      "Epoch 28/100\n",
      "174/174 [==============================] - 13s 76ms/step - loss: 1.4076 - accuracy: 0.4190 - val_loss: 1.5412 - val_accuracy: 0.4736\n",
      "Epoch 29/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 1.4254 - accuracy: 0.4124 - val_loss: 1.6735 - val_accuracy: 0.4764\n",
      "Epoch 30/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.4191 - accuracy: 0.4136 - val_loss: 1.5588 - val_accuracy: 0.4792\n",
      "Epoch 31/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.4403 - accuracy: 0.4133 - val_loss: 1.6025 - val_accuracy: 0.4688\n",
      "Epoch 32/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.4135 - accuracy: 0.4193 - val_loss: 1.5445 - val_accuracy: 0.4840\n",
      "Epoch 33/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.4448 - accuracy: 0.4087 - val_loss: 1.4535 - val_accuracy: 0.4750\n",
      "Epoch 34/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 1.4201 - accuracy: 0.4127 - val_loss: 1.4662 - val_accuracy: 0.4785\n",
      "Epoch 35/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.4414 - accuracy: 0.4124 - val_loss: 1.5767 - val_accuracy: 0.4701\n",
      "Epoch 36/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 1.4343 - accuracy: 0.4118 - val_loss: 1.6065 - val_accuracy: 0.4736\n",
      "Epoch 37/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.4280 - accuracy: 0.4141 - val_loss: 1.5987 - val_accuracy: 0.4743\n",
      "Epoch 38/100\n",
      "174/174 [==============================] - 10s 60ms/step - loss: 1.4204 - accuracy: 0.4136 - val_loss: 1.6801 - val_accuracy: 0.4736\n",
      "Epoch 39/100\n",
      "174/174 [==============================] - 13s 72ms/step - loss: 1.4272 - accuracy: 0.4159 - val_loss: 1.5186 - val_accuracy: 0.4743\n",
      "Epoch 40/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.4206 - accuracy: 0.4136 - val_loss: 1.5228 - val_accuracy: 0.4819\n",
      "Epoch 41/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.4382 - accuracy: 0.4185 - val_loss: 1.6511 - val_accuracy: 0.4743\n",
      "Epoch 42/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 1.4115 - accuracy: 0.4228 - val_loss: 1.7319 - val_accuracy: 0.4778\n",
      "Epoch 43/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.4533 - accuracy: 0.4156 - val_loss: 1.3861 - val_accuracy: 0.4694\n",
      "Epoch 44/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 1.4025 - accuracy: 0.4234 - val_loss: 1.6035 - val_accuracy: 0.4840\n",
      "Epoch 45/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.4192 - accuracy: 0.4240 - val_loss: 1.4356 - val_accuracy: 0.4799\n",
      "Epoch 46/100\n",
      "174/174 [==============================] - 11s 62ms/step - loss: 1.4141 - accuracy: 0.4159 - val_loss: 1.7589 - val_accuracy: 0.4840\n",
      "Epoch 47/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.4200 - accuracy: 0.4199 - val_loss: 1.5602 - val_accuracy: 0.4882\n",
      "Epoch 48/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.4214 - accuracy: 0.4176 - val_loss: 1.9343 - val_accuracy: 0.4736\n",
      "Epoch 49/100\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 1.4194 - accuracy: 0.4251 - val_loss: 1.5231 - val_accuracy: 0.4778\n",
      "Epoch 50/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.4038 - accuracy: 0.4309 - val_loss: 1.5364 - val_accuracy: 0.5340\n",
      "Epoch 51/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.3999 - accuracy: 0.4392 - val_loss: 1.3945 - val_accuracy: 0.5222\n",
      "Epoch 52/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.3553 - accuracy: 0.4745 - val_loss: 1.5245 - val_accuracy: 0.5486\n",
      "Epoch 53/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.3593 - accuracy: 0.4843 - val_loss: 1.3767 - val_accuracy: 0.5556\n",
      "Epoch 54/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.2671 - accuracy: 0.5227 - val_loss: 1.7251 - val_accuracy: 0.5590\n",
      "Epoch 55/100\n",
      "174/174 [==============================] - 12s 71ms/step - loss: 1.2569 - accuracy: 0.5336 - val_loss: 1.5722 - val_accuracy: 0.6250\n",
      "Epoch 56/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 1.2085 - accuracy: 0.5498 - val_loss: 1.5781 - val_accuracy: 0.6299\n",
      "Epoch 57/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 1.2135 - accuracy: 0.5498 - val_loss: 1.5455 - val_accuracy: 0.6444\n",
      "Epoch 58/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.2127 - accuracy: 0.5553 - val_loss: 1.7417 - val_accuracy: 0.6187\n",
      "Epoch 59/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 1.1509 - accuracy: 0.5714 - val_loss: 1.4441 - val_accuracy: 0.6514\n",
      "Epoch 60/100\n",
      "174/174 [==============================] - 11s 62ms/step - loss: 1.1579 - accuracy: 0.5732 - val_loss: 1.5626 - val_accuracy: 0.6458\n",
      "Epoch 61/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.1659 - accuracy: 0.5720 - val_loss: 1.3403 - val_accuracy: 0.6535\n",
      "Epoch 62/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 1.1383 - accuracy: 0.5850 - val_loss: 1.1759 - val_accuracy: 0.6674\n",
      "Epoch 63/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.1172 - accuracy: 0.5922 - val_loss: 1.4008 - val_accuracy: 0.6771\n",
      "Epoch 64/100\n",
      "174/174 [==============================] - 11s 60ms/step - loss: 1.1264 - accuracy: 0.5945 - val_loss: 1.5539 - val_accuracy: 0.6410\n",
      "Epoch 65/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.1271 - accuracy: 0.5913 - val_loss: 1.6364 - val_accuracy: 0.6285\n",
      "Epoch 66/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.1796 - accuracy: 0.5717 - val_loss: 1.3901 - val_accuracy: 0.6569\n",
      "Epoch 67/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.1292 - accuracy: 0.5873 - val_loss: 1.4316 - val_accuracy: 0.6646\n",
      "Epoch 68/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 1.1364 - accuracy: 0.5965 - val_loss: 1.3316 - val_accuracy: 0.6681\n",
      "Epoch 69/100\n",
      "174/174 [==============================] - 11s 63ms/step - loss: 1.1013 - accuracy: 0.6035 - val_loss: 1.5762 - val_accuracy: 0.6729\n",
      "Epoch 70/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.0703 - accuracy: 0.6078 - val_loss: 1.5561 - val_accuracy: 0.6660\n",
      "Epoch 71/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.0884 - accuracy: 0.6087 - val_loss: 1.5413 - val_accuracy: 0.6576\n",
      "Epoch 72/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.0699 - accuracy: 0.6216 - val_loss: 1.4621 - val_accuracy: 0.6854\n",
      "Epoch 73/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.0929 - accuracy: 0.6075 - val_loss: 1.7073 - val_accuracy: 0.6757\n",
      "Epoch 74/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.1345 - accuracy: 0.5965 - val_loss: 1.3756 - val_accuracy: 0.6528\n",
      "Epoch 75/100\n",
      "174/174 [==============================] - 11s 60ms/step - loss: 1.1010 - accuracy: 0.6061 - val_loss: 1.5659 - val_accuracy: 0.6944\n",
      "Epoch 76/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.0766 - accuracy: 0.6185 - val_loss: 1.5383 - val_accuracy: 0.6896\n",
      "Epoch 77/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 1.0293 - accuracy: 0.6392 - val_loss: 1.6445 - val_accuracy: 0.6792\n",
      "Epoch 78/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.0537 - accuracy: 0.6240 - val_loss: 1.8585 - val_accuracy: 0.6826\n",
      "Epoch 79/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.0569 - accuracy: 0.6300 - val_loss: 1.4767 - val_accuracy: 0.6646\n",
      "Epoch 80/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 1.0534 - accuracy: 0.6378 - val_loss: 1.6278 - val_accuracy: 0.6701\n",
      "Epoch 81/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.0924 - accuracy: 0.6104 - val_loss: 1.6211 - val_accuracy: 0.6528\n",
      "Epoch 82/100\n",
      "174/174 [==============================] - 10s 60ms/step - loss: 1.0465 - accuracy: 0.6214 - val_loss: 1.6348 - val_accuracy: 0.6569\n",
      "Epoch 83/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.0320 - accuracy: 0.6352 - val_loss: 1.9059 - val_accuracy: 0.6604\n",
      "Epoch 84/100\n",
      "174/174 [==============================] - 10s 60ms/step - loss: 1.0341 - accuracy: 0.6372 - val_loss: 1.8255 - val_accuracy: 0.6687\n",
      "Epoch 85/100\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 1.0974 - accuracy: 0.6268 - val_loss: 1.7474 - val_accuracy: 0.6479\n",
      "Epoch 86/100\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 1.0368 - accuracy: 0.6326 - val_loss: 1.5542 - val_accuracy: 0.6861\n",
      "Epoch 87/100\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 1.0404 - accuracy: 0.6277 - val_loss: 1.7604 - val_accuracy: 0.6819\n",
      "Epoch 88/100\n",
      "174/174 [==============================] - 11s 62ms/step - loss: 1.0648 - accuracy: 0.6346 - val_loss: 1.8343 - val_accuracy: 0.6743\n",
      "Epoch 89/100\n",
      "174/174 [==============================] - 11s 66ms/step - loss: 1.0780 - accuracy: 0.6214 - val_loss: 1.9730 - val_accuracy: 0.6729\n",
      "Epoch 90/100\n",
      "174/174 [==============================] - 11s 62ms/step - loss: 1.0372 - accuracy: 0.6381 - val_loss: 1.5769 - val_accuracy: 0.6632\n",
      "Epoch 91/100\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 1.0466 - accuracy: 0.6369 - val_loss: 1.5438 - val_accuracy: 0.6778\n",
      "Epoch 92/100\n",
      "174/174 [==============================] - 13s 72ms/step - loss: 1.0135 - accuracy: 0.6525 - val_loss: 1.4097 - val_accuracy: 0.6938\n",
      "Epoch 93/100\n",
      "174/174 [==============================] - 10s 59ms/step - loss: 1.0617 - accuracy: 0.6315 - val_loss: 1.3835 - val_accuracy: 0.6687\n",
      "Epoch 94/100\n",
      "174/174 [==============================] - 10s 57ms/step - loss: 1.0058 - accuracy: 0.6566 - val_loss: 1.6899 - val_accuracy: 0.6757\n",
      "Epoch 95/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.0351 - accuracy: 0.6395 - val_loss: 1.4702 - val_accuracy: 0.6965\n",
      "Epoch 96/100\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 1.0331 - accuracy: 0.6320 - val_loss: 1.6109 - val_accuracy: 0.6708\n",
      "Epoch 97/100\n",
      "174/174 [==============================] - 347s 2s/step - loss: 1.0220 - accuracy: 0.6505 - val_loss: 1.9003 - val_accuracy: 0.6632\n",
      "Epoch 98/100\n",
      "174/174 [==============================] - 16s 88ms/step - loss: 1.0141 - accuracy: 0.6519 - val_loss: 1.7068 - val_accuracy: 0.6771\n",
      "Epoch 99/100\n",
      "174/174 [==============================] - 16s 92ms/step - loss: 1.0077 - accuracy: 0.6447 - val_loss: 1.7136 - val_accuracy: 0.6806\n",
      "Epoch 100/100\n",
      "174/174 [==============================] - 16s 89ms/step - loss: 1.1538 - accuracy: 0.6017 - val_loss: 1.4634 - val_accuracy: 0.6583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb4c26d9510>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Conv2D( 32, (3,3), padding='same' , activation='relu', input_shape=(48,48,3)), \n",
    "    # pooling layer (Downsampling)\n",
    "    # downsize 2,2 pixels to 1,1\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    # Flatten-Dense\n",
    "    tf.keras.layers.Flatten(), \n",
    "    ## 1st layer\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"), # number inside Dense is the number of nodes. usually use 2^n\n",
    "    tf.keras.layers.Dropout(0.2), # helps prevent overfittng\n",
    "    ## second layer. we must have 7 final nodes because we have 7 classes.\n",
    "    tf.keras.layers.Dense(7, activation=\"softmax\") # softmax: compress resulting number between 0~1, used in category problems. If you add up the probability of each class we get 1. \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# compile and fit our model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\" , metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary of No Pre-Processing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                1179712   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,181,063\n",
      "Trainable params: 1,181,063\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3465 files belonging to 7 classes.\n",
      "Found 1440 files belonging to 7 classes.\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cropping2d_4 (Cropping2D)   (None, 28, 35, 3)         0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 28, 35, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 14, 17, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 7616)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                487488    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 488,839\n",
      "Trainable params: 488,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#dataset of cropped images\n",
    "crop_train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/Users/mantagaori/Desktop/comp473/COMP_473_Project/TrainSet2-new', \n",
    "    image_size = (48,48), # our original dataset is 48 pixels by 48 pixels\n",
    "    batch_size = 20 # pick 12 images and trin until all dataset is used <= repeat this for each epoche\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/Users/mantagaori/Desktop/comp473/COMP_473_Project/TestSet2-new', \n",
    "    image_size = (48,48), \n",
    "    batch_size = 20\n",
    ")\n",
    "\n",
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Cropping2D(cropping=((10,10),(10,3)), input_shape = (48, 48, 3)),\n",
    "    tf.keras.layers.Conv2D( 32, (3,3), padding='same' , activation='relu', input_shape=(48,48,3)), \n",
    "    # pooling layer (Downsampling)\n",
    "    # downsize 2,2 pixels to 1,1\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    # Flatten-Dense\n",
    "    tf.keras.layers.Flatten(), \n",
    "    ## 1st layer\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"), # number inside Dense is the number of nodes. usually use 2^n\n",
    "    tf.keras.layers.Dropout(0.2), # helps prevent overfittng\n",
    "    ## second layer. we must have 7 final nodes because we have 7 classes.\n",
    "    tf.keras.layers.Dense(7, activation=\"softmax\") # softmax: compress resulting number between 0~1, used in category problems. If you add up the probability of each class we get 1. \n",
    "])\n",
    "# model2.add(tf.keras.layers.Cropping2D(cropping=((10,10),(10,3))))\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# #example of a cropped input image\n",
    "# outputs_cropped = model2.predict(val_ds)\n",
    "# outputs = outputs_cropped[0]\n",
    "\n",
    "# #visualization\n",
    "# plt.imshow(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "174/174 [==============================] - 8s 35ms/step - loss: 16.1165 - accuracy: 0.3134 - val_loss: 1.6342 - val_accuracy: 0.4521\n",
      "Epoch 2/100\n",
      "174/174 [==============================] - 5s 29ms/step - loss: 1.6058 - accuracy: 0.4014 - val_loss: 1.5661 - val_accuracy: 0.4660\n",
      "Epoch 3/100\n",
      "174/174 [==============================] - 6s 31ms/step - loss: 1.5848 - accuracy: 0.4084 - val_loss: 1.5550 - val_accuracy: 0.4396\n",
      "Epoch 4/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 1.5302 - accuracy: 0.4081 - val_loss: 1.5100 - val_accuracy: 0.4667\n",
      "Epoch 5/100\n",
      "174/174 [==============================] - 6s 36ms/step - loss: 1.5162 - accuracy: 0.4055 - val_loss: 1.4983 - val_accuracy: 0.4674\n",
      "Epoch 6/100\n",
      "174/174 [==============================] - 5s 30ms/step - loss: 1.4875 - accuracy: 0.4124 - val_loss: 1.5170 - val_accuracy: 0.4653\n",
      "Epoch 7/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 1.5180 - accuracy: 0.4061 - val_loss: 1.4470 - val_accuracy: 0.4521\n",
      "Epoch 8/100\n",
      "174/174 [==============================] - 6s 32ms/step - loss: 1.4770 - accuracy: 0.4092 - val_loss: 1.4429 - val_accuracy: 0.4653\n",
      "Epoch 9/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 1.4780 - accuracy: 0.4072 - val_loss: 1.4722 - val_accuracy: 0.4667\n",
      "Epoch 10/100\n",
      "174/174 [==============================] - 6s 36ms/step - loss: 1.4734 - accuracy: 0.4087 - val_loss: 1.3970 - val_accuracy: 0.4625\n",
      "Epoch 11/100\n",
      "174/174 [==============================] - 7s 38ms/step - loss: 1.4734 - accuracy: 0.4046 - val_loss: 1.4963 - val_accuracy: 0.4639\n",
      "Epoch 12/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 1.4647 - accuracy: 0.4069 - val_loss: 1.4431 - val_accuracy: 0.4632\n",
      "Epoch 13/100\n",
      "174/174 [==============================] - 6s 35ms/step - loss: 1.4353 - accuracy: 0.4156 - val_loss: 1.5189 - val_accuracy: 0.4618\n",
      "Epoch 14/100\n",
      "174/174 [==============================] - 6s 36ms/step - loss: 1.4562 - accuracy: 0.4069 - val_loss: 1.4661 - val_accuracy: 0.4688\n",
      "Epoch 15/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 1.4307 - accuracy: 0.4141 - val_loss: 1.4389 - val_accuracy: 0.4688\n",
      "Epoch 16/100\n",
      "174/174 [==============================] - 7s 40ms/step - loss: 1.4306 - accuracy: 0.4110 - val_loss: 1.6122 - val_accuracy: 0.4674\n",
      "Epoch 17/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 1.4426 - accuracy: 0.4084 - val_loss: 1.5079 - val_accuracy: 0.4688\n",
      "Epoch 18/100\n",
      "174/174 [==============================] - 8s 43ms/step - loss: 1.4213 - accuracy: 0.4127 - val_loss: 1.5798 - val_accuracy: 0.4715\n",
      "Epoch 19/100\n",
      "174/174 [==============================] - 7s 39ms/step - loss: 1.4331 - accuracy: 0.4115 - val_loss: 1.4546 - val_accuracy: 0.4701\n",
      "Epoch 20/100\n",
      "174/174 [==============================] - 5s 27ms/step - loss: 1.4373 - accuracy: 0.4127 - val_loss: 1.5460 - val_accuracy: 0.4743\n",
      "Epoch 21/100\n",
      "174/174 [==============================] - 6s 36ms/step - loss: 1.4217 - accuracy: 0.4162 - val_loss: 1.4918 - val_accuracy: 0.4701\n",
      "Epoch 22/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 1.4180 - accuracy: 0.4156 - val_loss: 1.3991 - val_accuracy: 0.4694\n",
      "Epoch 23/100\n",
      "174/174 [==============================] - 6s 35ms/step - loss: 1.4164 - accuracy: 0.4162 - val_loss: 1.3582 - val_accuracy: 0.4715\n",
      "Epoch 24/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 1.4112 - accuracy: 0.4190 - val_loss: 1.3105 - val_accuracy: 0.4806\n",
      "Epoch 25/100\n",
      "174/174 [==============================] - 7s 42ms/step - loss: 1.3968 - accuracy: 0.4300 - val_loss: 1.2996 - val_accuracy: 0.4757\n",
      "Epoch 26/100\n",
      "174/174 [==============================] - 7s 40ms/step - loss: 1.3604 - accuracy: 0.4410 - val_loss: 1.2929 - val_accuracy: 0.4771\n",
      "Epoch 27/100\n",
      "174/174 [==============================] - 7s 42ms/step - loss: 1.4014 - accuracy: 0.4309 - val_loss: 1.2593 - val_accuracy: 0.4799\n",
      "Epoch 28/100\n",
      "174/174 [==============================] - 6s 35ms/step - loss: 1.4957 - accuracy: 0.4150 - val_loss: 1.2726 - val_accuracy: 0.4806\n",
      "Epoch 29/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 1.3866 - accuracy: 0.4364 - val_loss: 1.2870 - val_accuracy: 0.4826\n",
      "Epoch 30/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 1.3858 - accuracy: 0.4439 - val_loss: 1.5624 - val_accuracy: 0.4826\n",
      "Epoch 31/100\n",
      "174/174 [==============================] - 6s 35ms/step - loss: 1.3627 - accuracy: 0.4563 - val_loss: 1.2422 - val_accuracy: 0.4903\n",
      "Epoch 32/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 1.3195 - accuracy: 0.4586 - val_loss: 1.3487 - val_accuracy: 0.4965\n",
      "Epoch 33/100\n",
      "174/174 [==============================] - 6s 32ms/step - loss: 1.3475 - accuracy: 0.4548 - val_loss: 1.4428 - val_accuracy: 0.4979\n",
      "Epoch 34/100\n",
      "174/174 [==============================] - 6s 32ms/step - loss: 1.3365 - accuracy: 0.4678 - val_loss: 1.3070 - val_accuracy: 0.4910\n",
      "Epoch 35/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 1.3081 - accuracy: 0.4690 - val_loss: 1.2686 - val_accuracy: 0.5007\n",
      "Epoch 36/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 1.3611 - accuracy: 0.4540 - val_loss: 1.3995 - val_accuracy: 0.4979\n",
      "Epoch 37/100\n",
      "174/174 [==============================] - 6s 35ms/step - loss: 1.3318 - accuracy: 0.4745 - val_loss: 1.6363 - val_accuracy: 0.5007\n",
      "Epoch 38/100\n",
      "174/174 [==============================] - 6s 35ms/step - loss: 1.3772 - accuracy: 0.4537 - val_loss: 1.3367 - val_accuracy: 0.5014\n",
      "Epoch 39/100\n",
      "174/174 [==============================] - 6s 37ms/step - loss: 1.3446 - accuracy: 0.4681 - val_loss: 1.2718 - val_accuracy: 0.5104\n",
      "Epoch 40/100\n",
      "174/174 [==============================] - 6s 37ms/step - loss: 1.3256 - accuracy: 0.4719 - val_loss: 1.3136 - val_accuracy: 0.5076\n",
      "Epoch 41/100\n",
      "174/174 [==============================] - 6s 36ms/step - loss: 1.3279 - accuracy: 0.4693 - val_loss: 1.2839 - val_accuracy: 0.4986\n",
      "Epoch 42/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 1.3257 - accuracy: 0.4649 - val_loss: 1.1930 - val_accuracy: 0.4951\n",
      "Epoch 43/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 1.3197 - accuracy: 0.4687 - val_loss: 1.3419 - val_accuracy: 0.4965\n",
      "Epoch 44/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 1.3241 - accuracy: 0.4701 - val_loss: 1.2576 - val_accuracy: 0.5042\n",
      "Epoch 45/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 1.2923 - accuracy: 0.4765 - val_loss: 1.2277 - val_accuracy: 0.5014\n",
      "Epoch 46/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 1.3087 - accuracy: 0.4696 - val_loss: 1.4164 - val_accuracy: 0.5174\n",
      "Epoch 47/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 1.3412 - accuracy: 0.4739 - val_loss: 1.5338 - val_accuracy: 0.5285\n",
      "Epoch 48/100\n",
      "174/174 [==============================] - 6s 32ms/step - loss: 1.2620 - accuracy: 0.5250 - val_loss: 1.1065 - val_accuracy: 0.6549\n",
      "Epoch 49/100\n",
      "174/174 [==============================] - 6s 32ms/step - loss: 1.0369 - accuracy: 0.6136 - val_loss: 1.0630 - val_accuracy: 0.6750\n",
      "Epoch 50/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 0.9343 - accuracy: 0.6459 - val_loss: 0.8360 - val_accuracy: 0.6924\n",
      "Epoch 51/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 0.7696 - accuracy: 0.6949 - val_loss: 1.0464 - val_accuracy: 0.6826\n",
      "Epoch 52/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 0.7612 - accuracy: 0.7027 - val_loss: 0.9371 - val_accuracy: 0.7160\n",
      "Epoch 53/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 0.7025 - accuracy: 0.7189 - val_loss: 1.3013 - val_accuracy: 0.7153\n",
      "Epoch 54/100\n",
      "174/174 [==============================] - 6s 36ms/step - loss: 0.6710 - accuracy: 0.7258 - val_loss: 1.1799 - val_accuracy: 0.7201\n",
      "Epoch 55/100\n",
      "174/174 [==============================] - 6s 35ms/step - loss: 0.6461 - accuracy: 0.7267 - val_loss: 0.9980 - val_accuracy: 0.7306\n",
      "Epoch 56/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 0.6424 - accuracy: 0.7189 - val_loss: 1.0886 - val_accuracy: 0.7556\n",
      "Epoch 57/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 0.6170 - accuracy: 0.7434 - val_loss: 1.2998 - val_accuracy: 0.7431\n",
      "Epoch 58/100\n",
      "174/174 [==============================] - 6s 32ms/step - loss: 0.5959 - accuracy: 0.7530 - val_loss: 1.1771 - val_accuracy: 0.7451\n",
      "Epoch 59/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 0.5868 - accuracy: 0.7573 - val_loss: 1.0642 - val_accuracy: 0.7410\n",
      "Epoch 60/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 0.5737 - accuracy: 0.7622 - val_loss: 1.0127 - val_accuracy: 0.7590\n",
      "Epoch 61/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 0.5452 - accuracy: 0.7732 - val_loss: 1.3427 - val_accuracy: 0.7458\n",
      "Epoch 62/100\n",
      "174/174 [==============================] - 6s 36ms/step - loss: 0.5441 - accuracy: 0.7743 - val_loss: 1.3464 - val_accuracy: 0.7472\n",
      "Epoch 63/100\n",
      "174/174 [==============================] - 6s 35ms/step - loss: 0.5420 - accuracy: 0.7821 - val_loss: 1.4330 - val_accuracy: 0.7403\n",
      "Epoch 64/100\n",
      "174/174 [==============================] - 6s 35ms/step - loss: 0.5308 - accuracy: 0.7775 - val_loss: 1.4536 - val_accuracy: 0.7389\n",
      "Epoch 65/100\n",
      "174/174 [==============================] - 6s 36ms/step - loss: 0.5344 - accuracy: 0.7778 - val_loss: 1.1444 - val_accuracy: 0.7549\n",
      "Epoch 66/100\n",
      "174/174 [==============================] - 6s 35ms/step - loss: 0.5290 - accuracy: 0.7818 - val_loss: 1.2729 - val_accuracy: 0.7486\n",
      "Epoch 67/100\n",
      "174/174 [==============================] - 6s 35ms/step - loss: 0.5178 - accuracy: 0.7939 - val_loss: 1.7239 - val_accuracy: 0.7493\n",
      "Epoch 68/100\n",
      "174/174 [==============================] - 6s 36ms/step - loss: 0.5449 - accuracy: 0.7740 - val_loss: 1.3372 - val_accuracy: 0.7479\n",
      "Epoch 69/100\n",
      "174/174 [==============================] - 7s 38ms/step - loss: 0.5110 - accuracy: 0.7948 - val_loss: 1.5272 - val_accuracy: 0.7403\n",
      "Epoch 70/100\n",
      "174/174 [==============================] - 6s 35ms/step - loss: 0.4768 - accuracy: 0.8049 - val_loss: 1.6755 - val_accuracy: 0.7361\n",
      "Epoch 71/100\n",
      "174/174 [==============================] - 6s 35ms/step - loss: 0.4896 - accuracy: 0.7974 - val_loss: 1.3451 - val_accuracy: 0.7472\n",
      "Epoch 72/100\n",
      "174/174 [==============================] - 6s 36ms/step - loss: 0.4583 - accuracy: 0.8133 - val_loss: 2.4098 - val_accuracy: 0.7271\n",
      "Epoch 73/100\n",
      "174/174 [==============================] - 6s 35ms/step - loss: 0.4878 - accuracy: 0.8017 - val_loss: 1.8605 - val_accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "174/174 [==============================] - 7s 41ms/step - loss: 0.4680 - accuracy: 0.8133 - val_loss: 1.8188 - val_accuracy: 0.7521\n",
      "Epoch 75/100\n",
      "174/174 [==============================] - 8s 48ms/step - loss: 0.4353 - accuracy: 0.8222 - val_loss: 1.8400 - val_accuracy: 0.7458\n",
      "Epoch 76/100\n",
      "174/174 [==============================] - 8s 44ms/step - loss: 0.4859 - accuracy: 0.8066 - val_loss: 2.0274 - val_accuracy: 0.7326\n",
      "Epoch 77/100\n",
      "174/174 [==============================] - 8s 44ms/step - loss: 0.5020 - accuracy: 0.7908 - val_loss: 1.7724 - val_accuracy: 0.7569\n",
      "Epoch 78/100\n",
      "174/174 [==============================] - 8s 46ms/step - loss: 0.4399 - accuracy: 0.8248 - val_loss: 2.0986 - val_accuracy: 0.7472\n",
      "Epoch 79/100\n",
      "174/174 [==============================] - 8s 47ms/step - loss: 0.4045 - accuracy: 0.8341 - val_loss: 1.7933 - val_accuracy: 0.7521\n",
      "Epoch 80/100\n",
      "174/174 [==============================] - 8s 43ms/step - loss: 0.4229 - accuracy: 0.8297 - val_loss: 1.7982 - val_accuracy: 0.7646\n",
      "Epoch 81/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 0.4127 - accuracy: 0.8372 - val_loss: 1.6771 - val_accuracy: 0.7514\n",
      "Epoch 82/100\n",
      "174/174 [==============================] - 7s 38ms/step - loss: 0.4003 - accuracy: 0.8442 - val_loss: 1.6616 - val_accuracy: 0.7688\n",
      "Epoch 83/100\n",
      "174/174 [==============================] - 6s 36ms/step - loss: 0.4481 - accuracy: 0.8156 - val_loss: 2.0159 - val_accuracy: 0.7361\n",
      "Epoch 84/100\n",
      "174/174 [==============================] - 6s 35ms/step - loss: 0.4014 - accuracy: 0.8421 - val_loss: 2.3457 - val_accuracy: 0.7424\n",
      "Epoch 85/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 0.4192 - accuracy: 0.8392 - val_loss: 1.4078 - val_accuracy: 0.7792\n",
      "Epoch 86/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 0.3686 - accuracy: 0.8569 - val_loss: 2.1970 - val_accuracy: 0.7271\n",
      "Epoch 87/100\n",
      "174/174 [==============================] - 6s 35ms/step - loss: 0.3568 - accuracy: 0.8589 - val_loss: 2.2186 - val_accuracy: 0.7576\n",
      "Epoch 88/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 0.3521 - accuracy: 0.8644 - val_loss: 2.3741 - val_accuracy: 0.7451\n",
      "Epoch 89/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 0.3343 - accuracy: 0.8782 - val_loss: 2.5450 - val_accuracy: 0.7465\n",
      "Epoch 90/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 0.3604 - accuracy: 0.8635 - val_loss: 1.6392 - val_accuracy: 0.7264\n",
      "Epoch 91/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 0.3504 - accuracy: 0.8687 - val_loss: 2.1302 - val_accuracy: 0.7347\n",
      "Epoch 92/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 0.3493 - accuracy: 0.8707 - val_loss: 1.6141 - val_accuracy: 0.7417\n",
      "Epoch 93/100\n",
      "174/174 [==============================] - 6s 34ms/step - loss: 0.3733 - accuracy: 0.8644 - val_loss: 1.7993 - val_accuracy: 0.7576\n",
      "Epoch 94/100\n",
      "174/174 [==============================] - 6s 32ms/step - loss: 0.3719 - accuracy: 0.8618 - val_loss: 2.2957 - val_accuracy: 0.7382\n",
      "Epoch 95/100\n",
      "174/174 [==============================] - 6s 32ms/step - loss: 0.3145 - accuracy: 0.8846 - val_loss: 2.2808 - val_accuracy: 0.7688\n",
      "Epoch 96/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 0.3100 - accuracy: 0.8863 - val_loss: 1.9992 - val_accuracy: 0.7708\n",
      "Epoch 97/100\n",
      "174/174 [==============================] - 7s 38ms/step - loss: 0.3053 - accuracy: 0.8924 - val_loss: 1.9303 - val_accuracy: 0.7806\n",
      "Epoch 98/100\n",
      "174/174 [==============================] - 6s 32ms/step - loss: 0.3293 - accuracy: 0.8837 - val_loss: 1.8726 - val_accuracy: 0.7632\n",
      "Epoch 99/100\n",
      "174/174 [==============================] - 6s 33ms/step - loss: 0.2696 - accuracy: 0.8961 - val_loss: 1.8007 - val_accuracy: 0.7854\n",
      "Epoch 100/100\n",
      "174/174 [==============================] - 6s 32ms/step - loss: 0.2761 - accuracy: 0.8993 - val_loss: 1.6544 - val_accuracy: 0.8007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb1fc5a3b10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\" , metrics=['accuracy'])\n",
    "model2.fit(crop_train_ds, validation_data=val_ds, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96762580dc771c728ac9a1b8aa29a3a420bc09545a8c1a32553175fbb1f6eb2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
