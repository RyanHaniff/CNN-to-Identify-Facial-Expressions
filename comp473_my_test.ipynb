{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "MyQ4QFbZVhuG"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UB6z6XFaWdcv",
    "outputId": "c1b8540b-5e75-4fdd-c50e-6f4d89436a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2760 files belonging to 7 classes.\n",
      "Found 1440 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# get training and validation(=testing) data\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../COMP_473_Project/TrainSet1-new',\n",
    "    image_size = (48,48), # our original dataset is 48 pixels by 48 pixels\n",
    "    batch_size = 12, # pick 12 images and trim until all dataset is used <= repeat this for each epoche\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../COMP_473_Project/TestSet1-new',\n",
    "    image_size = (48,48), \n",
    "    batch_size = 12,\n",
    "    color_mode='grayscale'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDTPOOojvWc4",
    "outputId": "307a2019-d9ec-4c0c-9bfa-7c02d28c28b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<BatchDataset element_spec=(TensorSpec(shape=(None, 48, 48, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds \n",
    "# form shape=(None, 48, 48, 3) <- 3 represent that the photo is treated as colored. one pixel will have [R G B] values between 0~255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nlxVewnivXWB",
    "outputId": "cdfa1795-48ef-413a-c428-962b243be067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]]\n",
      "\n",
      "\n",
      " [[[85.]\n",
      "   [86.]\n",
      "   [88.]\n",
      "   ...\n",
      "   [14.]\n",
      "   [29.]\n",
      "   [79.]]\n",
      "\n",
      "  [[85.]\n",
      "   [85.]\n",
      "   [83.]\n",
      "   ...\n",
      "   [21.]\n",
      "   [11.]\n",
      "   [46.]]\n",
      "\n",
      "  [[85.]\n",
      "   [86.]\n",
      "   [74.]\n",
      "   ...\n",
      "   [23.]\n",
      "   [14.]\n",
      "   [23.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[63.]\n",
      "   [66.]\n",
      "   [66.]\n",
      "   ...\n",
      "   [38.]\n",
      "   [46.]\n",
      "   [62.]]\n",
      "\n",
      "  [[63.]\n",
      "   [64.]\n",
      "   [64.]\n",
      "   ...\n",
      "   [36.]\n",
      "   [45.]\n",
      "   [61.]]\n",
      "\n",
      "  [[61.]\n",
      "   [62.]\n",
      "   [64.]\n",
      "   ...\n",
      "   [35.]\n",
      "   [49.]\n",
      "   [65.]]]\n",
      "\n",
      "\n",
      " [[[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]]], shape=(12, 48, 48, 1), dtype=float32)\n",
      "tf.Tensor([0 4 4 4 2 6 5 2 2 2 6 1], shape=(12,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'In a grayscale image where there is only one channel, a pixel value has just a single number ranging from 0 to 255 (both inclusive).\\n The pixel value 0 represents black and the pixel value 255 represents white.\\n [ 80.] is closer to black than white therefore showing black'"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to output one of our image\n",
    "\n",
    "for i, answer in train_ds.take(1): #take(1): takes first batch. \n",
    "\n",
    "  print(i) # outputs 12(=batch size) photos as numpy array ,shape=(12, 48, 48, 3) means 12 photos, each photo size(48,48 pixels), 3=color= each cell represented as [R G B]\n",
    "  print(answer) # outputs correct answer for current batch [ 5 2 6 ...] <- first photo in this batch is in class 5, second photo in this patch is in class 2.. \n",
    "\n",
    "plt.imshow(i[0].numpy().astype('uint8'), cmap='gray', vmin=0, vmax=255) # output the first photo using matplotlib\n",
    "plt.show()\n",
    "'''In a grayscale image where there is only one channel, a pixel value has just a single number ranging from 0 to 255 (both inclusive).\n",
    " The pixel value 0 represents black and the pixel value 255 represents white.\n",
    " [ 80.] is closer to black than white therefore showing black'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "pEoV-cdH1lGq"
   },
   "outputs": [],
   "source": [
    "# preprocess colored data\n",
    "# since the numbers are between 0~255 for each R, G, and B, it is slower to train and calculate weights.\n",
    "# it is better to divide each number with 255, so each value resides within 0~1\n",
    "\n",
    "\n",
    "\n",
    "def processGrayScaleData(i, answer):\n",
    "  i=tf.cast(i/255.0, tf.float32) # divide i by 255, resulting data type should be float\n",
    "  return i, answer\n",
    "\n",
    "train_ds = train_ds.map(processGrayScaleData)\n",
    "val_ds = val_ds.map(processGrayScaleData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bid7gMcW1se5",
    "outputId": "b760f03f-92c5-49d5-cf67-54a4d31e2849"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.40392157]\n",
      "   [0.4117647 ]\n",
      "   [0.22745098]\n",
      "   ...\n",
      "   [0.50980395]\n",
      "   [0.4745098 ]\n",
      "   [0.59607846]]\n",
      "\n",
      "  [[0.4       ]\n",
      "   [0.47843137]\n",
      "   [0.30980393]\n",
      "   ...\n",
      "   [0.50980395]\n",
      "   [0.5254902 ]\n",
      "   [0.6784314 ]]\n",
      "\n",
      "  [[0.36862746]\n",
      "   [0.47843137]\n",
      "   [0.5019608 ]\n",
      "   ...\n",
      "   [0.49803922]\n",
      "   [0.46666667]\n",
      "   [0.5803922 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.44313726]\n",
      "   [0.45882353]\n",
      "   [0.4745098 ]\n",
      "   ...\n",
      "   [0.5294118 ]\n",
      "   [0.5176471 ]\n",
      "   [0.50980395]]\n",
      "\n",
      "  [[0.4509804 ]\n",
      "   [0.45882353]\n",
      "   [0.47058824]\n",
      "   ...\n",
      "   [0.5254902 ]\n",
      "   [0.5137255 ]\n",
      "   [0.50980395]]\n",
      "\n",
      "  [[0.44313726]\n",
      "   [0.44705883]\n",
      "   [0.45490196]\n",
      "   ...\n",
      "   [0.5254902 ]\n",
      "   [0.5176471 ]\n",
      "   [0.49803922]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.33333334]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.03137255]\n",
      "   [0.31764707]\n",
      "   ...\n",
      "   [0.11764706]\n",
      "   [0.07058824]\n",
      "   [0.03921569]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.04705882]\n",
      "   [0.29803923]\n",
      "   ...\n",
      "   [0.4627451 ]\n",
      "   [0.44313726]\n",
      "   [0.41568628]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.45882353]\n",
      "   [0.45882353]\n",
      "   [0.45882353]\n",
      "   ...\n",
      "   [0.5058824 ]\n",
      "   [0.1254902 ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.04313726]\n",
      "   [0.07058824]\n",
      "   ...\n",
      "   [0.49803922]\n",
      "   [0.07843138]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.49411765]\n",
      "   [0.04705882]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.35686275]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.01960784]\n",
      "   [0.03921569]\n",
      "   ...\n",
      "   [0.3019608 ]\n",
      "   [0.02745098]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.21568628]\n",
      "   [0.22352941]\n",
      "   [0.25490198]\n",
      "   ...\n",
      "   [0.27450982]\n",
      "   [0.04313726]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.10980392]\n",
      "   [0.4392157 ]\n",
      "   ...\n",
      "   [0.6       ]\n",
      "   [0.59607846]\n",
      "   [0.6       ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.06666667]\n",
      "   [0.43137255]\n",
      "   ...\n",
      "   [0.14901961]\n",
      "   [0.09411765]\n",
      "   [0.05490196]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.03921569]\n",
      "   [0.42745098]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]], shape=(12, 48, 48, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# try to output our image if 'processColoredData' function is working well.\n",
    "for i, answer in train_ds.take(1): #take first batch \n",
    "  print(i) # now you can see that the values are compressed btw 0~1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pi4bprpl1_3u",
    "outputId": "22c60923-5deb-4d96-9177-08e5b8a0f982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 48, 48, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 24, 24, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 12, 12, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 6, 6, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                294976    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388,103\n",
      "Trainable params: 388,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "230/230 [==============================] - 5s 17ms/step - loss: 1.5000 - accuracy: 0.4007 - val_loss: 1.0076 - val_accuracy: 0.6611\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.6924 - accuracy: 0.7304 - val_loss: 0.8077 - val_accuracy: 0.7181\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.4273 - accuracy: 0.8293 - val_loss: 0.7196 - val_accuracy: 0.7417\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3056 - accuracy: 0.8801 - val_loss: 0.7427 - val_accuracy: 0.7875\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.2525 - accuracy: 0.9112 - val_loss: 0.5923 - val_accuracy: 0.8146\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.1743 - accuracy: 0.9355 - val_loss: 0.8055 - val_accuracy: 0.7708\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.1419 - accuracy: 0.9460 - val_loss: 0.7537 - val_accuracy: 0.7917\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.1694 - accuracy: 0.9355 - val_loss: 0.7248 - val_accuracy: 0.7965\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.1144 - accuracy: 0.9580 - val_loss: 0.8284 - val_accuracy: 0.8090\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.1171 - accuracy: 0.9558 - val_loss: 0.9280 - val_accuracy: 0.8201\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1f6cd558310>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making model\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "\n",
    "    # .conv2D : with feature extraction we can expect higher accuracy               \n",
    "    # 1st param: make 32 different features. use such features to train better model. \n",
    "    # 2nd param: kernel size is 3x3\n",
    "    # 3rd param: when using convolutional layer, (=when kernel is applied to each photo) the size of photo will shrink. we will put some padding here to retain 48*48 size even after feature extraction.\n",
    "    # 4th param: activation function. relu compress number to 0~1. There's no negative number in photo so it is good to use relu.\n",
    "    # 5th param: input_shape : shape of one photo data\n",
    "    tf.keras.layers.Conv2D( 32, (3,3), padding='same' , activation='relu', input_shape=(48,48,1)), # set input_shape=(48,48,3) from 3 to 1 since we are passing in grayscale\n",
    "    \n",
    "    \n",
    "    # pooling layer (Downsampling)\n",
    "    # downsize 2,2 pixels to 1,1\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    # helps prevent overfittng ( randomly sets input units to 0 with frequency of rate)\n",
    "    tf.keras.layers.Dropout(0.2), \n",
    "\n",
    "    # It is okay to repeat [Conv-Pooling] several times\n",
    "    # we will repeat [Conv-Pooling] two more times to increase learning effect\n",
    "    tf.keras.layers.Conv2D( 64, (3,3), padding='same' , activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D((2,2)), \n",
    "        \n",
    "    tf.keras.layers.Conv2D( 128, (3,3), padding='same' , activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D((2,2)), \n",
    "\n",
    "\n",
    "    # Flatten-Dense\n",
    "    tf.keras.layers.Flatten(), \n",
    "    ## 1st layer\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"), # number inside Dense is the number of nodes. usually use 2^n\n",
    "    tf.keras.layers.Dropout(0.2), # helps prevent overfittng\n",
    "    ## second layer. we must have 7 final nodes because we have 7 classes.\n",
    "    tf.keras.layers.Dense(7, activation=\"softmax\") # softmax: compress resulting number between 0~1, used in category problems. If you add up the probability of each class we get 1. \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# prints summary of our model. \n",
    "model.summary()\n",
    "\n",
    "\n",
    "# compile and fit our model\n",
    "# epochs tells us the number of times model will be trained in forward and backward pass.\n",
    "# validation_data is used to feed the validation/test data into the model.\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\" , metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Save model weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "model.save('model_saved.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting a test set:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1440 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../COMP_473_Project/model_saved.h5')\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../COMP_473_Project/TestSet2-new',\n",
    "    image_size = (48,48),\n",
    "    batch_size = 12,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "test_ds = test_ds.map(processGrayScaleData)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.19215687]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.01960784]\n",
      "   [0.19607843]\n",
      "   ...\n",
      "   [0.04705882]\n",
      "   [0.03529412]\n",
      "   [0.02352941]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.03137255]\n",
      "   [0.20784314]\n",
      "   ...\n",
      "   [0.16862746]\n",
      "   [0.23921569]\n",
      "   [0.26666668]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.        ]\n",
      "   [0.99215686]\n",
      "   [0.9098039 ]\n",
      "   ...\n",
      "   [0.99215686]\n",
      "   [0.2509804 ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.09411765]\n",
      "   [0.14117648]\n",
      "   ...\n",
      "   [1.        ]\n",
      "   [0.15686275]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [1.        ]\n",
      "   [0.09411765]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.85882354]\n",
      "   [0.85882354]\n",
      "   [0.8627451 ]\n",
      "   ...\n",
      "   [0.15686275]\n",
      "   [0.3529412 ]\n",
      "   [0.6313726 ]]\n",
      "\n",
      "  [[0.8627451 ]\n",
      "   [0.85490197]\n",
      "   [0.8392157 ]\n",
      "   ...\n",
      "   [0.13725491]\n",
      "   [0.15686275]\n",
      "   [0.4862745 ]]\n",
      "\n",
      "  [[0.8509804 ]\n",
      "   [0.8509804 ]\n",
      "   [0.8235294 ]\n",
      "   ...\n",
      "   [0.12941177]\n",
      "   [0.14901961]\n",
      "   [0.20784314]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7019608 ]\n",
      "   [0.6901961 ]\n",
      "   [0.6784314 ]\n",
      "   ...\n",
      "   [0.57254905]\n",
      "   [0.6117647 ]\n",
      "   [0.61960787]]\n",
      "\n",
      "  [[0.69803923]\n",
      "   [0.68235296]\n",
      "   [0.6745098 ]\n",
      "   ...\n",
      "   [0.58431375]\n",
      "   [0.60784316]\n",
      "   [0.6156863 ]]\n",
      "\n",
      "  [[0.6901961 ]\n",
      "   [0.6784314 ]\n",
      "   [0.6666667 ]\n",
      "   ...\n",
      "   [0.59607846]\n",
      "   [0.6039216 ]\n",
      "   [0.6156863 ]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.43529412]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.00784314]\n",
      "   [0.00784314]\n",
      "   ...\n",
      "   [0.44705883]\n",
      "   [0.04313726]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.27450982]\n",
      "   [0.10588235]\n",
      "   [0.04313726]\n",
      "   ...\n",
      "   [0.4509804 ]\n",
      "   [0.07058824]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.07058824]\n",
      "   [0.27450982]\n",
      "   ...\n",
      "   [0.20392157]\n",
      "   [0.44705883]\n",
      "   [0.53333336]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.04313726]\n",
      "   [0.27450982]\n",
      "   ...\n",
      "   [0.04705882]\n",
      "   [0.07058824]\n",
      "   [0.05098039]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.02352941]\n",
      "   [0.26666668]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.03137255]\n",
      "   [0.02352941]\n",
      "   [0.00784314]\n",
      "   ...\n",
      "   [0.00784314]\n",
      "   [0.00784314]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.03137255]\n",
      "   [0.01568628]\n",
      "   [0.00392157]\n",
      "   ...\n",
      "   [0.00392157]\n",
      "   [0.00392157]\n",
      "   [0.00392157]]\n",
      "\n",
      "  [[0.02745098]\n",
      "   [0.00392157]\n",
      "   [0.00784314]\n",
      "   ...\n",
      "   [0.00784314]\n",
      "   [0.00392157]\n",
      "   [0.00392157]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03137255]\n",
      "   [0.00784314]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.01960784]\n",
      "   [0.00784314]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.07058824]\n",
      "   [0.04705882]\n",
      "   [0.03137255]\n",
      "   ...\n",
      "   [0.00392157]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.40784314]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.03921569]\n",
      "   [0.40784314]\n",
      "   ...\n",
      "   [0.05098039]\n",
      "   [0.03529412]\n",
      "   [0.02745098]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.06666667]\n",
      "   [0.40784314]\n",
      "   ...\n",
      "   [0.2       ]\n",
      "   [0.23921569]\n",
      "   [0.28235295]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.21960784]\n",
      "   [0.3254902 ]\n",
      "   [0.5764706 ]\n",
      "   ...\n",
      "   [0.43137255]\n",
      "   [0.10980392]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.03137255]\n",
      "   [0.09803922]\n",
      "   ...\n",
      "   [0.42745098]\n",
      "   [0.06666667]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.43137255]\n",
      "   [0.03921569]\n",
      "   [0.        ]]]], shape=(12, 48, 48, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Test to see if output is okay\n",
    "for i, answer in test_ds.take(1): #take first batch\n",
    "  print(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Predicting the test dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "3.679374e-07\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "8.2944305e-17\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1.0014624e-08\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "2.0888673e-11\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "6.461513e-08\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0.9994973\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.9976903\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.9999696\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "5.6525257e-10\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0.0010337534\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1.7250706e-17\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "8.8805785e-07\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1.7120208e-14\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1.8353178e-19\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "4.15504e-11\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "4.206718e-12\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "4.091116e-14\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "6.22408e-05\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "5.88177e-16\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0.0004036677\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1.8004455e-10\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2.3129654e-17\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1.8893661e-16\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2.4281532e-22\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "2.9919274e-28\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "6.1420633e-13\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1.4614474e-18\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2.891105e-07\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1.055665e-18\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "3.6918245e-17\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "8.711734e-11\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1.4674859e-07\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "4.4166255e-12\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.0004698405\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "0.00043341098\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "7.883856e-09\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "9.1711526e-12\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1.13397e-15\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.9999993\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0.9965507\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "3.5708542e-06\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2.5485305e-08\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "8.505065e-25\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1.0068343e-19\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "5.314344e-16\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2.4779497e-17\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2.321537e-27\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "2.1574476e-07\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "5.0966323e-06\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "7.133036e-08\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2.6879082e-08\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "8.1518614e-08\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0.9999101\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "9.743579e-13\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "4.5728506e-17\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "5.8292086e-17\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.00068396825\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "3.684179e-07\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "5.6637606e-07\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "7.875669e-22\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0.99988985\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "2.4873e-11\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "2.6073984e-19\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "3.2193706e-22\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.72749144\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1.4571487e-12\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1.9083194e-19\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.0007235073\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "3.0041254e-16\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "6.372556e-16\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2.1876932e-07\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "3.4543908e-05\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "8.059381e-17\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.83309895\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "5.472512e-22\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.008939636\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "2.6306965e-05\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "4.53243e-13\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "8.1219347e-14\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "3.7394574e-20\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1.7258894e-14\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1.3584313e-17\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "4.722753e-06\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "0.99850684\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "4.906479e-16\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "7.932864e-06\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1.1410743e-09\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "3.0889096e-13\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1.0539481e-10\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "8.552663e-06\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "7.067878e-05\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1.2714608e-21\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "5.4893152e-09\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "0.23921245\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0.9998272\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.0014901698\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.97357166\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "5.8552974e-08\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.9999802\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2.1666401e-12\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "4.2131107e-09\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "7.97119e-12\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.9995365\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2.4733337e-08\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0.9999987\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "8.810986e-14\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0.99993825\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "3.4528643e-05\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "0.02425857\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0.17512554\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1.368755e-10\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "7.4782097e-10\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "6.1789944e-15\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "5.251089e-09\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "9.285e-17\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "0.99932384\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "5.6801487e-21\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "9.073854e-18\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "5.6020795e-28\n"
     ]
    }
   ],
   "source": [
    "# from keras.utils import load_img\n",
    "#\n",
    "# image = load_img('../COMP_473_Project/TestSet2-new/anger/S066_005_00000009n1.png', target_size=(48, 48))\n",
    "# img = np.array(image)\n",
    "# img = img / 255.0\n",
    "# img = img.reshape(1,48,48,1)\n",
    "# label = model.predict(img)\n",
    "# print(\"Predicted Class (0 - Cars , 1- Planes): \", label[0][0])\n",
    "\n",
    "\n",
    "for img in test_ds:\n",
    "    label = model.predict(img[0])\n",
    "    print(label[0][0])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "96762580dc771c728ac9a1b8aa29a3a420bc09545a8c1a32553175fbb1f6eb2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
