{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3465 files belonging to 7 classes.\n",
      "Found 1440 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# get training and validation(=testing) data\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/Users/mantagaori/Desktop/comp473/COMP_473_Project/TrainSet2-new', \n",
    "    image_size = (48,48), # our original dataset is 48 pixels by 48 pixels\n",
    "    batch_size = 20 # pick 12 images and trin until all dataset is used <= repeat this for each epoche\n",
    ")\n",
    "\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/Users/mantagaori/Desktop/comp473/COMP_473_Project/TestSet2-new', \n",
    "    image_size = (48,48), \n",
    "    batch_size = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "174/174 [==============================] - 17s 85ms/step - loss: 18.7310 - accuracy: 0.2234 - val_loss: 1.7503 - val_accuracy: 0.2500\n",
      "Epoch 2/100\n",
      "174/174 [==============================] - 13s 72ms/step - loss: 1.6567 - accuracy: 0.3541 - val_loss: 1.5375 - val_accuracy: 0.4646\n",
      "Epoch 3/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 1.5257 - accuracy: 0.4087 - val_loss: 1.4781 - val_accuracy: 0.4660\n",
      "Epoch 4/100\n",
      "174/174 [==============================] - 13s 73ms/step - loss: 1.5073 - accuracy: 0.4035 - val_loss: 1.4931 - val_accuracy: 0.4674\n",
      "Epoch 5/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 1.5488 - accuracy: 0.3887 - val_loss: 1.4338 - val_accuracy: 0.4611\n",
      "Epoch 6/100\n",
      "174/174 [==============================] - 14s 82ms/step - loss: 1.4807 - accuracy: 0.4043 - val_loss: 1.4423 - val_accuracy: 0.4667\n",
      "Epoch 7/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.4508 - accuracy: 0.4107 - val_loss: 1.3845 - val_accuracy: 0.4681\n",
      "Epoch 8/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.4570 - accuracy: 0.4061 - val_loss: 1.4305 - val_accuracy: 0.4681\n",
      "Epoch 9/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 1.4486 - accuracy: 0.4118 - val_loss: 1.4418 - val_accuracy: 0.4688\n",
      "Epoch 10/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.4424 - accuracy: 0.4115 - val_loss: 1.5316 - val_accuracy: 0.4667\n",
      "Epoch 11/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.4254 - accuracy: 0.4127 - val_loss: 1.6143 - val_accuracy: 0.4667\n",
      "Epoch 12/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.4402 - accuracy: 0.4095 - val_loss: 1.5693 - val_accuracy: 0.4674\n",
      "Epoch 13/100\n",
      "174/174 [==============================] - 13s 72ms/step - loss: 1.4212 - accuracy: 0.4173 - val_loss: 1.5223 - val_accuracy: 0.4694\n",
      "Epoch 14/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.4294 - accuracy: 0.4084 - val_loss: 1.4492 - val_accuracy: 0.4694\n",
      "Epoch 15/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.4507 - accuracy: 0.4055 - val_loss: 1.6578 - val_accuracy: 0.4694\n",
      "Epoch 16/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 1.4465 - accuracy: 0.4147 - val_loss: 1.4521 - val_accuracy: 0.4569\n",
      "Epoch 17/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 1.4628 - accuracy: 0.4023 - val_loss: 1.6564 - val_accuracy: 0.4694\n",
      "Epoch 18/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.4204 - accuracy: 0.4150 - val_loss: 1.6199 - val_accuracy: 0.4681\n",
      "Epoch 19/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.4460 - accuracy: 0.4078 - val_loss: 1.4751 - val_accuracy: 0.4674\n",
      "Epoch 20/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.4339 - accuracy: 0.4101 - val_loss: 1.5849 - val_accuracy: 0.4688\n",
      "Epoch 21/100\n",
      "174/174 [==============================] - 11s 63ms/step - loss: 1.4521 - accuracy: 0.4055 - val_loss: 1.5529 - val_accuracy: 0.4694\n",
      "Epoch 22/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.4234 - accuracy: 0.4170 - val_loss: 1.6206 - val_accuracy: 0.4736\n",
      "Epoch 23/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.4263 - accuracy: 0.4165 - val_loss: 1.8541 - val_accuracy: 0.4604\n",
      "Epoch 24/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.4307 - accuracy: 0.4101 - val_loss: 1.4837 - val_accuracy: 0.4736\n",
      "Epoch 25/100\n",
      "174/174 [==============================] - 12s 71ms/step - loss: 1.4518 - accuracy: 0.4078 - val_loss: 1.6048 - val_accuracy: 0.4694\n",
      "Epoch 26/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.4198 - accuracy: 0.4153 - val_loss: 1.4973 - val_accuracy: 0.4833\n",
      "Epoch 27/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 1.4291 - accuracy: 0.4089 - val_loss: 1.5139 - val_accuracy: 0.4722\n",
      "Epoch 28/100\n",
      "174/174 [==============================] - 13s 76ms/step - loss: 1.4076 - accuracy: 0.4190 - val_loss: 1.5412 - val_accuracy: 0.4736\n",
      "Epoch 29/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 1.4254 - accuracy: 0.4124 - val_loss: 1.6735 - val_accuracy: 0.4764\n",
      "Epoch 30/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.4191 - accuracy: 0.4136 - val_loss: 1.5588 - val_accuracy: 0.4792\n",
      "Epoch 31/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.4403 - accuracy: 0.4133 - val_loss: 1.6025 - val_accuracy: 0.4688\n",
      "Epoch 32/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.4135 - accuracy: 0.4193 - val_loss: 1.5445 - val_accuracy: 0.4840\n",
      "Epoch 33/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.4448 - accuracy: 0.4087 - val_loss: 1.4535 - val_accuracy: 0.4750\n",
      "Epoch 34/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 1.4201 - accuracy: 0.4127 - val_loss: 1.4662 - val_accuracy: 0.4785\n",
      "Epoch 35/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.4414 - accuracy: 0.4124 - val_loss: 1.5767 - val_accuracy: 0.4701\n",
      "Epoch 36/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 1.4343 - accuracy: 0.4118 - val_loss: 1.6065 - val_accuracy: 0.4736\n",
      "Epoch 37/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.4280 - accuracy: 0.4141 - val_loss: 1.5987 - val_accuracy: 0.4743\n",
      "Epoch 38/100\n",
      "174/174 [==============================] - 10s 60ms/step - loss: 1.4204 - accuracy: 0.4136 - val_loss: 1.6801 - val_accuracy: 0.4736\n",
      "Epoch 39/100\n",
      "174/174 [==============================] - 13s 72ms/step - loss: 1.4272 - accuracy: 0.4159 - val_loss: 1.5186 - val_accuracy: 0.4743\n",
      "Epoch 40/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.4206 - accuracy: 0.4136 - val_loss: 1.5228 - val_accuracy: 0.4819\n",
      "Epoch 41/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.4382 - accuracy: 0.4185 - val_loss: 1.6511 - val_accuracy: 0.4743\n",
      "Epoch 42/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 1.4115 - accuracy: 0.4228 - val_loss: 1.7319 - val_accuracy: 0.4778\n",
      "Epoch 43/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.4533 - accuracy: 0.4156 - val_loss: 1.3861 - val_accuracy: 0.4694\n",
      "Epoch 44/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 1.4025 - accuracy: 0.4234 - val_loss: 1.6035 - val_accuracy: 0.4840\n",
      "Epoch 45/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.4192 - accuracy: 0.4240 - val_loss: 1.4356 - val_accuracy: 0.4799\n",
      "Epoch 46/100\n",
      "174/174 [==============================] - 11s 62ms/step - loss: 1.4141 - accuracy: 0.4159 - val_loss: 1.7589 - val_accuracy: 0.4840\n",
      "Epoch 47/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.4200 - accuracy: 0.4199 - val_loss: 1.5602 - val_accuracy: 0.4882\n",
      "Epoch 48/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.4214 - accuracy: 0.4176 - val_loss: 1.9343 - val_accuracy: 0.4736\n",
      "Epoch 49/100\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 1.4194 - accuracy: 0.4251 - val_loss: 1.5231 - val_accuracy: 0.4778\n",
      "Epoch 50/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.4038 - accuracy: 0.4309 - val_loss: 1.5364 - val_accuracy: 0.5340\n",
      "Epoch 51/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.3999 - accuracy: 0.4392 - val_loss: 1.3945 - val_accuracy: 0.5222\n",
      "Epoch 52/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.3553 - accuracy: 0.4745 - val_loss: 1.5245 - val_accuracy: 0.5486\n",
      "Epoch 53/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.3593 - accuracy: 0.4843 - val_loss: 1.3767 - val_accuracy: 0.5556\n",
      "Epoch 54/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.2671 - accuracy: 0.5227 - val_loss: 1.7251 - val_accuracy: 0.5590\n",
      "Epoch 55/100\n",
      "174/174 [==============================] - 12s 71ms/step - loss: 1.2569 - accuracy: 0.5336 - val_loss: 1.5722 - val_accuracy: 0.6250\n",
      "Epoch 56/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 1.2085 - accuracy: 0.5498 - val_loss: 1.5781 - val_accuracy: 0.6299\n",
      "Epoch 57/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 1.2135 - accuracy: 0.5498 - val_loss: 1.5455 - val_accuracy: 0.6444\n",
      "Epoch 58/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.2127 - accuracy: 0.5553 - val_loss: 1.7417 - val_accuracy: 0.6187\n",
      "Epoch 59/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 1.1509 - accuracy: 0.5714 - val_loss: 1.4441 - val_accuracy: 0.6514\n",
      "Epoch 60/100\n",
      "174/174 [==============================] - 11s 62ms/step - loss: 1.1579 - accuracy: 0.5732 - val_loss: 1.5626 - val_accuracy: 0.6458\n",
      "Epoch 61/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.1659 - accuracy: 0.5720 - val_loss: 1.3403 - val_accuracy: 0.6535\n",
      "Epoch 62/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 1.1383 - accuracy: 0.5850 - val_loss: 1.1759 - val_accuracy: 0.6674\n",
      "Epoch 63/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.1172 - accuracy: 0.5922 - val_loss: 1.4008 - val_accuracy: 0.6771\n",
      "Epoch 64/100\n",
      "174/174 [==============================] - 11s 60ms/step - loss: 1.1264 - accuracy: 0.5945 - val_loss: 1.5539 - val_accuracy: 0.6410\n",
      "Epoch 65/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.1271 - accuracy: 0.5913 - val_loss: 1.6364 - val_accuracy: 0.6285\n",
      "Epoch 66/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.1796 - accuracy: 0.5717 - val_loss: 1.3901 - val_accuracy: 0.6569\n",
      "Epoch 67/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.1292 - accuracy: 0.5873 - val_loss: 1.4316 - val_accuracy: 0.6646\n",
      "Epoch 68/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 1.1364 - accuracy: 0.5965 - val_loss: 1.3316 - val_accuracy: 0.6681\n",
      "Epoch 69/100\n",
      "174/174 [==============================] - 11s 63ms/step - loss: 1.1013 - accuracy: 0.6035 - val_loss: 1.5762 - val_accuracy: 0.6729\n",
      "Epoch 70/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.0703 - accuracy: 0.6078 - val_loss: 1.5561 - val_accuracy: 0.6660\n",
      "Epoch 71/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.0884 - accuracy: 0.6087 - val_loss: 1.5413 - val_accuracy: 0.6576\n",
      "Epoch 72/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.0699 - accuracy: 0.6216 - val_loss: 1.4621 - val_accuracy: 0.6854\n",
      "Epoch 73/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.0929 - accuracy: 0.6075 - val_loss: 1.7073 - val_accuracy: 0.6757\n",
      "Epoch 74/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.1345 - accuracy: 0.5965 - val_loss: 1.3756 - val_accuracy: 0.6528\n",
      "Epoch 75/100\n",
      "174/174 [==============================] - 11s 60ms/step - loss: 1.1010 - accuracy: 0.6061 - val_loss: 1.5659 - val_accuracy: 0.6944\n",
      "Epoch 76/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.0766 - accuracy: 0.6185 - val_loss: 1.5383 - val_accuracy: 0.6896\n",
      "Epoch 77/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 1.0293 - accuracy: 0.6392 - val_loss: 1.6445 - val_accuracy: 0.6792\n",
      "Epoch 78/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 1.0537 - accuracy: 0.6240 - val_loss: 1.8585 - val_accuracy: 0.6826\n",
      "Epoch 79/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 1.0569 - accuracy: 0.6300 - val_loss: 1.4767 - val_accuracy: 0.6646\n",
      "Epoch 80/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 1.0534 - accuracy: 0.6378 - val_loss: 1.6278 - val_accuracy: 0.6701\n",
      "Epoch 81/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.0924 - accuracy: 0.6104 - val_loss: 1.6211 - val_accuracy: 0.6528\n",
      "Epoch 82/100\n",
      "174/174 [==============================] - 10s 60ms/step - loss: 1.0465 - accuracy: 0.6214 - val_loss: 1.6348 - val_accuracy: 0.6569\n",
      "Epoch 83/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 1.0320 - accuracy: 0.6352 - val_loss: 1.9059 - val_accuracy: 0.6604\n",
      "Epoch 84/100\n",
      "174/174 [==============================] - 10s 60ms/step - loss: 1.0341 - accuracy: 0.6372 - val_loss: 1.8255 - val_accuracy: 0.6687\n",
      "Epoch 85/100\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 1.0974 - accuracy: 0.6268 - val_loss: 1.7474 - val_accuracy: 0.6479\n",
      "Epoch 86/100\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 1.0368 - accuracy: 0.6326 - val_loss: 1.5542 - val_accuracy: 0.6861\n",
      "Epoch 87/100\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 1.0404 - accuracy: 0.6277 - val_loss: 1.7604 - val_accuracy: 0.6819\n",
      "Epoch 88/100\n",
      "174/174 [==============================] - 11s 62ms/step - loss: 1.0648 - accuracy: 0.6346 - val_loss: 1.8343 - val_accuracy: 0.6743\n",
      "Epoch 89/100\n",
      "174/174 [==============================] - 11s 66ms/step - loss: 1.0780 - accuracy: 0.6214 - val_loss: 1.9730 - val_accuracy: 0.6729\n",
      "Epoch 90/100\n",
      "174/174 [==============================] - 11s 62ms/step - loss: 1.0372 - accuracy: 0.6381 - val_loss: 1.5769 - val_accuracy: 0.6632\n",
      "Epoch 91/100\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 1.0466 - accuracy: 0.6369 - val_loss: 1.5438 - val_accuracy: 0.6778\n",
      "Epoch 92/100\n",
      "174/174 [==============================] - 13s 72ms/step - loss: 1.0135 - accuracy: 0.6525 - val_loss: 1.4097 - val_accuracy: 0.6938\n",
      "Epoch 93/100\n",
      "174/174 [==============================] - 10s 59ms/step - loss: 1.0617 - accuracy: 0.6315 - val_loss: 1.3835 - val_accuracy: 0.6687\n",
      "Epoch 94/100\n",
      "174/174 [==============================] - 10s 57ms/step - loss: 1.0058 - accuracy: 0.6566 - val_loss: 1.6899 - val_accuracy: 0.6757\n",
      "Epoch 95/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 1.0351 - accuracy: 0.6395 - val_loss: 1.4702 - val_accuracy: 0.6965\n",
      "Epoch 96/100\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 1.0331 - accuracy: 0.6320 - val_loss: 1.6109 - val_accuracy: 0.6708\n",
      "Epoch 97/100\n",
      "174/174 [==============================] - 347s 2s/step - loss: 1.0220 - accuracy: 0.6505 - val_loss: 1.9003 - val_accuracy: 0.6632\n",
      "Epoch 98/100\n",
      "174/174 [==============================] - 16s 88ms/step - loss: 1.0141 - accuracy: 0.6519 - val_loss: 1.7068 - val_accuracy: 0.6771\n",
      "Epoch 99/100\n",
      "174/174 [==============================] - 16s 92ms/step - loss: 1.0077 - accuracy: 0.6447 - val_loss: 1.7136 - val_accuracy: 0.6806\n",
      "Epoch 100/100\n",
      "174/174 [==============================] - 16s 89ms/step - loss: 1.1538 - accuracy: 0.6017 - val_loss: 1.4634 - val_accuracy: 0.6583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb4c26d9510>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Conv2D( 32, (3,3), padding='same' , activation='relu', input_shape=(48,48,3)), \n",
    "    # pooling layer (Downsampling)\n",
    "    # downsize 2,2 pixels to 1,1\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    # Flatten-Dense\n",
    "    tf.keras.layers.Flatten(), \n",
    "    ## 1st layer\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"), # number inside Dense is the number of nodes. usually use 2^n\n",
    "    tf.keras.layers.Dropout(0.2), # helps prevent overfittng\n",
    "    ## second layer. we must have 7 final nodes because we have 7 classes.\n",
    "    tf.keras.layers.Dense(7, activation=\"softmax\") # softmax: compress resulting number between 0~1, used in category problems. If you add up the probability of each class we get 1. \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# compile and fit our model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\" , metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary of No Pre-Processing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                1179712   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,181,063\n",
      "Trainable params: 1,181,063\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96762580dc771c728ac9a1b8aa29a3a420bc09545a8c1a32553175fbb1f6eb2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
